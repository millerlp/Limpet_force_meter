---
title: "Limpet force meter analysis code"
author: ""
date: ""
output: word_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(replace.assign=TRUE,width=60)
knitr::opts_chunk$set(tidy=FALSE)
showcode = FALSE
```


```{r loadPackages, cache=FALSE}
# library(circular)  # Call this as needed below, since it masks mean() and sd()
library(RColorBrewer) 
library(plotrix)
library(RANN) # for nn2 nearest neighbor search function
library(png)
```

```{r calibrationFunctions, cache = TRUE, echo = showcode}
#################################################################################
## Function loadCalibFile
## This function imports a calibration data file (.csv) with 4 columns of data
## that should be titled 'axis', 'direction', 'mass.grams', 'analogValue'.
## The input should be the file name and directory of the file
## The output will be a dataframe holding the data. 
loadCalibFile = function(fname = 'CalibrationFiles_Apr202016.csv' ,
		fdir = 'Dropbox/Limpet_force_meter/'){
	# Determine which computer we're working on so we can put the appropriate
	# file path prefix on the Dropbox file directory
	platform = .Platform$OS.type
	if (platform == 'unix'){
		prefixDrive = '~/'
	} else if (platform == 'windows'){
		prefixDrive = 'D:/'
	}
	
	fdir = paste0(prefixDrive,fdir)
	
	# Import the calibration data file
	calib = read.csv(paste0(fdir,fname))	
}
#################################################################################


################################################################################
# Function plotSeparateAxesCalib
# A function to plot the individual positive and negative calibration data for
# each of the axes (X, Y, Z). This includes the zero values for a particular 
# axis in each plot of the positive or negative direction. Note that the Z 
# axis only has one direction (positive = downwards)
# Input a data frame imported from the raw calibration data file

plotSeparateAxesCalib = function(calib = calib){
# Pull apart the separate axes calibration data, and include the zero values
	xpos = calib[calib$axis == 'X' & (calib$direction == 'zero' | 
						calib$direction == 'positive'),]
	xpos = droplevels(xpos)
	
	xneg = calib[calib$axis == 'X' & (calib$direction == 'zero' | 
						calib$direction == 'negative'),]
	xneg = droplevels(xneg)
	
	ypos = calib[calib$axis == 'Y' & (calib$direction == 'zero' | 
						calib$direction == 'positive'),]
	ypos = droplevels(ypos)
	
	yneg = calib[calib$axis == 'Y' & (calib$direction == 'zero' | 
						calib$direction == 'negative'),]
	yneg = droplevels(yneg)
	
	zneg = calib[calib$axis == 'Z' & (calib$direction == 'zero' | 
						calib$direction == 'negative'),]
	zneg = droplevels(zneg)

# Plot the raw data for each axis
	par(mfrow = c(3,2))
	#############################
# Positive X-axis
	plot(x = xpos$analogValue, y = xpos$mass.grams, type='p', 
			xlab = 'Analog count',
			ylab = 'Mass, g',
			main = 'X axis positive')
	mod = lm(mass.grams~analogValue, data = xpos)
	modSum = summary(mod)
	abline(mod)
	r2 = modSum$adj.r.squared
	mylabel = bquote(italic(R)^2 == .(format(r2, digits = 3)))
	legend('topleft', legend = mylabel, bty = 'n')
	###########################
# Negative X-axis
	plot(x = xneg$analogValue, y = xneg$mass.grams, type='p', 
			xlab = 'Analog count',
			ylab = 'Mass, g',
			main = 'X axis negative')
	mod = lm(mass.grams~analogValue, data = xneg)
	modSum = summary(mod)
	abline(mod)
	r2 = modSum$adj.r.squared
	mylabel = bquote(italic(R)^2 == .(format(r2, digits = 3)))
	legend('topright', legend = mylabel, bty = 'n')
	#######################
# Positive Y axis
	plot(x = ypos$analogValue, y = ypos$mass.grams, type='p', 
			xlab = 'Analog count',
			ylab = 'Mass, g',
			main = 'Y axis positive')
	mod = lm(mass.grams~analogValue, data = ypos)
	modSum = summary(mod)
	abline(mod)
	r2 = modSum$adj.r.squared
	mylabel = bquote(italic(R)^2 == .(format(r2, digits = 3)))
	legend('topleft', legend = mylabel, bty = 'n')
	###########################
# Negative Y-axis
	plot(x = yneg$analogValue, y = yneg$mass.grams, type='p', 
			xlab = 'Analog count',
			ylab = 'Mass, g',
			main = 'Y axis negative')
	mod = lm(mass.grams~analogValue, data = yneg)
	modSum = summary(mod)
	abline(mod)
	r2 =  modSum$adj.r.squared
	mylabel = bquote(italic(R)^2 == .(format(r2, digits = 3)))
	legend('topright', legend = mylabel, bty = 'n')
	#######################
# Z-axis
	plot(x = zneg$analogValue, y = zneg$mass.grams, type='p', 
			xlab = 'Analog count',
			ylab = 'Mass, g',
			main = 'Z axis negative')
	mod = lm(mass.grams~analogValue, data = zneg)
	modSum = summary(mod)
	abline(mod)
	r2 =  modSum$adj.r.squared
	mylabel = bquote(italic(R)^2 == .(format(r2, digits = 3)))
	legend('topleft', legend = mylabel, bty = 'n')	
}  # end of plotSeparateAxesCalib

#############################################################################
# Produce a list of calibration coefficients for the three axes. 
# The output will be a list with entries X, Y, Z, each containing a field
# 'intercept','slope', and 'R2' (R-squared)
# The regression coefficients intercept and slope will convert an input 
# analogValue into an estimate of Force (Newtons), with a positive or negative
# value depending on the direction of the force application. 

calibCoefficients = function(calib = calib){
	#########################################
	xax = calib[calib$axis == 'X',]
# Convert mass into force (Newtons) by multiplying by gravity acceleration
	xax$Force.N = (xax$mass.grams/1000) * 9.8066
# Make negative-direction values into negative forces
	xax$Force.N[xax$direction == 'negative'] = -1 * 
			xax$Force.N[xax$direction=='negative']
	#########################################
# Y-axis all data, converted to force in Newtons
	yax = calib[calib$axis == 'Y',]
# Convert mass into force (Newtons) by multiplying by gravity acceleration
	yax$Force.N = (yax$mass.grams/1000) * 9.8066
# Make negative-direction values into negative forces
	yax$Force.N[yax$direction == 'negative'] = -1 * 
			yax$Force.N[yax$direction=='negative']	
	############################################
# Z-axis all data, converted to force in Newtons
	zax = calib[calib$axis == 'Z',]
# Convert mass into force (Newtons) by multiplying by gravity acceleration
	zax$Force.N = (zax$mass.grams/1000) * 9.8066
# Make negative-direction values into negative forces
	zax$Force.N[zax$direction == 'negative'] = -1 * 
			zax$Force.N[zax$direction=='negative']
	################################################
	# Fit regressions for each axis
	modX = lm(Force.N~analogValue, data = xax)
	modXSum = summary(modX)
	# Extract intercept, slope, R^2 of regression
	myinterceptX = coef(modXSum)[1,1]
	myslopeX = coef(modXSum)[2,1]
	r2X =  modXSum$adj.r.squared
	################
	modY = lm(Force.N~analogValue, data = yax)
	modYSum = summary(modY)
	# Extract intercept, slope, R^2 of regression
	myinterceptY = coef(modYSum)[1,1]
	myslopeY = coef(modYSum)[2,1]
	r2Y =  modYSum$adj.r.squared
	################
	modZ = lm(Force.N~analogValue, data = zax)
	modZSum = summary(modZ)
	# Extract intercept, slope, R^2 of regression
	myinterceptZ = coef(modZSum)[1,1]
	myslopeZ = coef(modZSum)[2,1]
	r2Z =  modZSum$adj.r.squared
	###############################################
	# Combine data into an output list
	output = list(X = data.frame(intercept = myinterceptX, slope = myslopeX, 
					R2 = r2X),
			Y = data.frame(intercept = myinterceptY, slope = myslopeY,R2 = r2Y),
			Z= data.frame(intercept = myinterceptZ, slope = myslopeZ,R2 = r2Z))
	output
}
################################################################################


################################################################################
# Function plotAxesCalib
# This function will produce three plots (one per axis X, Y, Z) to show the 
# calibration data and regression fit to those data. The regression will use
# analogValue as the x-axis, and force in newtons (converted from mass in grams)
# for the y-axis. 
# Input should be a data frame of calibration data, with a column 'axis', 
# 'direction', 'mass.grams', and 'analogValue', produced by importing the
# raw calibration data file  

plotAxesCalib = function(calib = calib){
	######################################################
	# Combine all data for a single axis into one set, convert to force units,
	# estimate regression fit. 
	######################################################
	# X-axis all data, converted to force in Newtons
	par(mfrow=c(3,1))
	xax = calib[calib$axis == 'X',]
	# Convert mass into force (Newtons) by multiplying by gravity acceleration
	xax$Force.N = (xax$mass.grams/1000) * 9.8066
	# Make negative-direction values into negative forces
	xax$Force.N[xax$direction == 'negative'] = -1 * 
			xax$Force.N[xax$direction=='negative']
	
	plot(x = xax$analogValue, y = xax$Force.N,las = 1,
			xlab = 'Analog Count',
			ylab = 'Force, N',
			main = 'X axis')
	abline(h = 0, lty = 2, col = 'grey70')
	# Fit regression
	modX = lm(Force.N~analogValue, data = xax)
	modXSum = summary(modX)
	abline(modX)
	myinterceptX = coef(modXSum)[1,1]
	myslopeX = coef(modXSum)[2,1]
	r2 =  modXSum$adj.r.squared
	
	# Start by making an expression vector to hold the 2 lines of output:
	rp = vector('expression',2)
	
	# Write the first line, which will give R-squared and 
	# pull the value from the data frame wt.fits
	# The double == prints an equal sign when used inside expression()
	rp[1] = substitute(expression(italic(R)^2 == MYVALUE),
			list(MYVALUE = format(r2,digits = 4)))[2]
	
	# Write the 2nd line, which will pull 2 values from data frame wt.fits:
	rp[2] = substitute(expression(italic(Y) == MYVALUE2 + MYVALUE3*x),
			list(MYVALUE2 = format(myinterceptX, digits = 3),
					MYVALUE3 = format(myslopeX,digits = 3)))[2]
	# Finally, simply plot with legend() function:
	legend('topleft', legend = rp, bty = 'n')
	
	############################################
	# Y-axis all data, converted to force in Newtons
	yax = calib[calib$axis == 'Y',]
	# Convert mass into force (Newtons) by multiplying by gravity acceleration
	yax$Force.N = (yax$mass.grams/1000) * 9.8066
	# Make negative-direction values into negative forces
	yax$Force.N[yax$direction == 'negative'] = -1 * 
			yax$Force.N[yax$direction=='negative']
	
	plot(x = yax$analogValue, y = yax$Force.N,las = 1,
			xlab = 'Analog Count',
			ylab = 'Force, N',
			main = 'Y axis')
	abline(h = 0, lty = 2, col = 'grey70')
	# Fit regression
	modY = lm(Force.N~analogValue, data = yax)
	modYSum = summary(modY)
	abline(modY)
	myinterceptY = coef(modYSum)[1,1]
	myslopeY = coef(modYSum)[2,1]
	r2 =  modYSum$adj.r.squared
	
	# Start by making an expression vector to hold the 2 lines of output:
	rp = vector('expression',2)
	
	# Write the first line, which will give R-squared and 
	# pull the value from the data frame wt.fits
	# The double == prints an equal sign when used inside expression()
	rp[1] = substitute(expression(italic(R)^2 == MYVALUE),
			list(MYVALUE = format(r2,digits = 4)))[2]
	
	# Write the 2nd line, which will pull 2 values from data frame wt.fits:
	rp[2] = substitute(expression(italic(Y) == MYVALUE2 + MYVALUE3*x),
			list(MYVALUE2 = format(myinterceptY, digits = 3),
					MYVALUE3 = format(myslopeY,digits = 3)))[2]
	# Finally, simply plot with legend() function:
	legend('topleft', legend = rp, bty = 'n')
	
	############################################
	# Z-axis all data, converted to force in Newtons
	zax = calib[calib$axis == 'Z',]
	# Convert mass into force (Newtons) by multiplying by gravity acceleration
	zax$Force.N = (zax$mass.grams/1000) * 9.8066
	# Make negative-direction values into negative forces
	zax$Force.N[zax$direction == 'negative'] = -1 * 
			zax$Force.N[zax$direction=='negative']
	
	plot(x = zax$analogValue, y = zax$Force.N, las = 1,
			xlab = 'Analog Count',
			ylab = 'Force, N',
			main = 'Z axis')
	abline(h = 0, lty = 2, col = 'grey70')
	# Fit regression
	modZ = lm(Force.N~analogValue, data = zax)
	modZSum = summary(modZ)
	abline(modZ)
	myinterceptZ = coef(modZSum)[1,1]
	myslopeZ = coef(modZSum)[2,1]
	r2 =  modZSum$adj.r.squared
	
	# Start by making an expression vector to hold the 2 lines of output:
	rp = vector('expression',2)
	
	# Write the first line, which will give R-squared and 
	# pull the value from the data frame wt.fits
	# The double == prints an equal sign when used inside expression()
	rp[1] = substitute(expression(italic(R)^2 == MYVALUE),
			list(MYVALUE = format(r2,digits = 4)))[2]
	
	# Write the 2nd line, which will pull 2 values from data frame wt.fits:
	rp[2] = substitute(expression(italic(Y) == MYVALUE2 + MYVALUE3*x),
			list(MYVALUE2 = format(myinterceptZ, digits = 3),
					MYVALUE3 = format(myslopeZ,digits = 3)))[2]
	# Finally, simply plot with legend() function:
	legend('topright', legend = rp, bty = 'n')	
}
###############################################################################

```
  

The calibration data for the positive Y-axis on 2016-12-14 appear to be no 
good in the summary calibration file. The connector for this transducer axis was
not functional. In order to still use the data from the 2016-12-15 trial, we can
instead use the same calibration from 2016-12-13, which is the closest 
previous calibration. For some of the other calibration events, data for
certain masses appear to be erroneous (possibly due to the wrong mass value 
being entered during calibration). The code removes potentially spurious 
calibration data points, and the calibration data that end up being used in the
analysis are plotted below. 

Note that the April 2016 trial data should not be analyzed, as the z-axis was
not working. For the May 2016 trials, the closest available calibration data
were from Apr 20 2016, so that calibration is used. The raw data from that
calibration aren't available currently, so we have to use the summary
calibration data (means of the analog output value at each mass).

```{r importRawCalib20161213, echo=showcode, cache=TRUE, fig.cap="Calibration data from 2016-12-13",fig.width=8,fig.height=10}
cdir = "./Data/CAL files raw data/"

fnames = dir(cdir)
################################################################################
# Process the 2016-12-13 calibration data
# For CAL_20161213_1714_00.csv file, on the X-axis, ignore the 2000g readings
# on positive side because the mass was mis-entered (was actually 2500g)

# For CAL_20161213_1714_00.csv file, on the Y-axis, ignore the 2000g reading
# on the negative side, and ignore both the 2500 + 2800 g values on the positive
# side. 

rawCal = read.csv(paste0(cdir,'CAL_20161213_1714_00.csv'))
# Find the mean analogValue when mass.grams == 0, this can be used to split up
# the data into the two directions of the x-axis. 
zeroval = mean(rawCal[(rawCal$axis == 'X') & (rawCal$mass.grams == 0),
				'analogValue'])
# Split out all the 'negative' values for X
negativeX = rawCal[(rawCal$axis == 'X') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue < zeroval),]
negativeX = rbind(negativeX, rawCal[(rawCal$axis == 'X') & 
						(rawCal$mass.grams == 0),])
negativeX$direction = 'negative'
negativeX$Date = as.Date('2016-12-13')
#summary(lm(mass.grams~analogValue, data = negativeX))
########################################################
# Split out all the 'positive' values for X
positiveX = rawCal[(rawCal$axis == 'X') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue > zeroval),]
positiveX =  rbind(positiveX, rawCal[(rawCal$axis == 'X') & 
						(rawCal$mass.grams == 0),])
# Remove the values at 2000g because they are spurious
positiveX = positiveX[positiveX$mass.grams != 2000,]
positiveX$direction = 'positive'
positiveX$Date = as.Date('2016-12-13')
#summary(lm(mass.grams~analogValue, data = positiveX))
####################################################
# Split out negative Y values
zeroval = mean(rawCal[(rawCal$axis == 'Y') & (rawCal$mass.grams == 0),
				'analogValue'])
# Split out all the 'negative' values for Y
negativeY = rawCal[(rawCal$axis == 'Y') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue < zeroval),]
negativeY = rbind(negativeY, rawCal[(rawCal$axis == 'Y') & 
						(rawCal$mass.grams == 0),])
# Remove the 2000g data from the negative Y side because they are spurious
negativeY = negativeY[negativeY$mass.grams != 2000,]
negativeY$direction = 'negative'
negativeY$Date = as.Date('2016-12-13')
#plot(mass.grams~analogValue, data = negativeY)
#summary(lm(mass.grams~analogValue, data = negativeY))
#######################################################
# Split out all the 'positive' values for Y
positiveY= rawCal[(rawCal$axis == 'Y') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue > zeroval),]
positiveY = rbind(positiveY, rawCal[(rawCal$axis == 'Y') & 
						(rawCal$mass.grams == 0),])
# Remove both the 2500 and 2800 g entries from the positive Y side because they
# are spurious
positiveY = positiveY[positiveY$mass.grams != 2500,]
positiveY = positiveY[positiveY$mass.grams != 2800,]
positiveY$direction = 'positive'
positiveY$Date = as.Date('2016-12-13')
#plot(mass.grams~analogValue, data = positiveY)
#summary(lm(mass.grams~analogValue, data = positiveY))
##############################################
# Split out the Z-axis data as well. 
positiveZ = rawCal[rawCal$axis == 'Z',]
positiveZ$direction = 'positive'
positiveZ$Date = as.Date('2016-12-13')
#summary(lm(mass.grams~analogValue, data = positiveZ))
# Concatenate into one data frame
calibs = rbind(negativeX,positiveX,negativeY,positiveY,positiveZ)

par(mfrow = c(3,2))
plot(mass.grams~analogValue, data = negativeX, main = 'X, 2016-12-13')
plot(mass.grams~analogValue, data = positiveX, main = 'X, 2016-12-13')
plot(mass.grams~analogValue, data = negativeY, main = 'Y, 2016-12-13')
plot(mass.grams~analogValue, data = positiveY, main = 'Y, 2016-12-13')
plot(mass.grams~analogValue, data = positiveZ, main = 'Z, 2016-12-13')

```


```{r importRawCalib20170104, echo=showcode,cache=TRUE,fig.cap="Calibration data from 2016-01-04",fig.width=8,fig.height=10}
# Repeat for the next calibration file
rawCal = read.csv(paste0(cdir,'CAL_20170104_1131_00.csv'))
# Find the mean analogValue when mass.grams == 0, this can be used to split up
# the data into the two directions of the x-axis. 
zeroval = mean(rawCal[(rawCal$axis == 'X') & (rawCal$mass.grams == 0),
				'analogValue'])
# Split out all the 'negative' values for X
negativeX = rawCal[(rawCal$axis == 'X') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue < zeroval),]
negativeX = rbind(negativeX, rawCal[(rawCal$axis == 'X') & 
						(rawCal$mass.grams == 0),])
# Remove the spurious 2000g data on the negative side
negativeX = negativeX[negativeX$mass.grams != 2000,]
negativeX$direction = 'negative'
negativeX$Date = as.Date('2017-01-04')
#plot(mass.grams~analogValue, data = negativeX)
#summary(lm(mass.grams~analogValue, data = negativeX))
########################################################
# Split out all the 'positive' values for X
positiveX = rawCal[(rawCal$axis == 'X') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue > zeroval),]
positiveX =  rbind(positiveX, rawCal[(rawCal$axis == 'X') & 
						(rawCal$mass.grams == 0),])

# Remove the values at 500g because they are spurious
positiveX = positiveX[positiveX$mass.grams != 500,]
#plot(mass.grams~analogValue, data = positiveX)
#summary(lm(mass.grams~analogValue, data = positiveX))
positiveX$direction = 'positive'
positiveX$Date = as.Date('2017-01-04')
####################################################
# Split out negative Y values
zeroval = mean(rawCal[(rawCal$axis == 'Y') & (rawCal$mass.grams == 0),
				'analogValue'])
# Split out all the 'negative' values for Y
negativeY = rawCal[(rawCal$axis == 'Y') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue < zeroval),]
negativeY = rbind(negativeY, rawCal[(rawCal$axis == 'Y') & 
						(rawCal$mass.grams == 0),])
# Remove 2000, 2500, 2800g values, all appear questionable
negativeY = negativeY[negativeY$mass.grams != 2000,]
negativeY = negativeY[negativeY$mass.grams != 2500,]
negativeY = negativeY[negativeY$mass.grams != 2800,]
#plot(mass.grams~analogValue, data = negativeY)
#summary(lm(mass.grams~analogValue, data = negativeY))
negativeY$direction = 'negative'
negativeY$Date = as.Date('2017-01-04')
#######################################################
# Split out all the 'positive' values for Y
positiveY= rawCal[(rawCal$axis == 'Y') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue > zeroval),]
positiveY = rbind(positiveY, rawCal[(rawCal$axis == 'Y') & 
						(rawCal$mass.grams == 0),])
# Remove both the 2000, 2500 & 2800g entries from the positive Y side because 
# they appear spurious
positiveY = positiveY[positiveY$mass.grams != 2000,]
positiveY = positiveY[positiveY$mass.grams != 2500,]
positiveY = positiveY[positiveY$mass.grams != 2800,]
#plot(mass.grams~analogValue, data = positiveY)
#summary(lm(mass.grams~analogValue, data = positiveY))
positiveY$direction = 'positive'
positiveY$Date = as.Date('2017-01-04')
##############################################
# Split out the Z-axis data as well. 
positiveZ = rawCal[rawCal$axis == 'Z',]
positiveZ$direction = 'positive'
positiveZ$Date = as.Date('2017-01-04')
#plot(mass.grams~analogValue, data = positiveZ)
#summary(lm(mass.grams~analogValue, data = positiveZ))
# Concatenate into one data frame
calibs = rbind(calibs, negativeX,positiveX,negativeY,positiveY,positiveZ)

par(mfrow = c(3,2))
plot(mass.grams~analogValue, data = negativeX, main = 'X, 2017-01-04')
plot(mass.grams~analogValue, data = positiveX, main = 'X, 2017-01-04')
plot(mass.grams~analogValue, data = negativeY, main = 'Y, 2017-01-04')
plot(mass.grams~analogValue, data = positiveY, main = 'Y, 2017-01-04')
plot(mass.grams~analogValue, data = positiveZ, main = 'Z, 2017-01-04')

################################################################################
################################################################################
```

```{r importRawCalib20170105, echo=showcode,cache=TRUE,fig.cap="Calibration data from 2017-01-05",fig.width=8,fig.height=10}
# Repeat for the next calibration file
rawCal = read.csv(paste0(cdir,'CAL_20170105_1438_00.csv'))
# Find the mean analogValue when mass.grams == 0, this can be used to split up
# the data into the two directions of the x-axis. 
zeroval = mean(rawCal[(rawCal$axis == 'X') & (rawCal$mass.grams == 0),
				'analogValue'])
# Split out all the 'negative' values for X
negativeX = rawCal[(rawCal$axis == 'X') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue < zeroval),]
negativeX = rbind(negativeX, rawCal[(rawCal$axis == 'X') & 
						(rawCal$mass.grams == 0),])
# Remove the spurious 2500 & 2800g data on the negative side
negativeX = negativeX[negativeX$mass.grams != 2500,]
negativeX = negativeX[negativeX$mass.grams != 2800,]
negativeX$direction = 'negative'
negativeX$Date = as.Date('2017-01-05')
#plot(mass.grams~analogValue, data = negativeX)
#summary(lm(mass.grams~analogValue, data = negativeX))
########################################################
# Split out all the 'positive' values for X
positiveX = rawCal[(rawCal$axis == 'X') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue > zeroval),]
positiveX =  rbind(positiveX, rawCal[(rawCal$axis == 'X') & 
						(rawCal$mass.grams == 0),])

# Remove the values at 2500 & 2800g because they don't look stable
#positiveX = positiveX[positiveX$mass.grams != 2000,]
positiveX = positiveX[positiveX$mass.grams != 2500,]
positiveX = positiveX[positiveX$mass.grams != 2800,]
#plot(mass.grams~analogValue, data = positiveX)
#summary(lm(mass.grams~analogValue, data = positiveX))
positiveX$direction = 'positive'
positiveX$Date = as.Date('2017-01-05')
####################################################
# Split out negative Y values
zeroval = mean(rawCal[(rawCal$axis == 'Y') & (rawCal$mass.grams == 0),
				'analogValue'])
# Split out all the 'negative' values for Y
negativeY = rawCal[(rawCal$axis == 'Y') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue < zeroval),]
negativeY = rbind(negativeY, rawCal[(rawCal$axis == 'Y') & 
						(rawCal$mass.grams == 0),])
# The 1000g trial appears to be a repeat of the 500g trial
negativeY = negativeY[negativeY$mass.grams != 1000,]
#plot(mass.grams~analogValue, data = negativeY)
#summary(lm(mass.grams~analogValue, data = negativeY))

negativeY$direction = 'negative'
negativeY$Date = as.Date('2017-01-05')
#######################################################
# Split out all the 'positive' values for Y
positiveY= rawCal[(rawCal$axis == 'Y') & (rawCal$mass.grams > 0) & 
				(rawCal$analogValue > zeroval),]
positiveY = rbind(positiveY, rawCal[(rawCal$axis == 'Y') & 
						(rawCal$mass.grams == 0),])

# Remove the 2000, 2500 & 2800 g entries from the positive Y side because they
# appear spurious
positiveY = positiveY[positiveY$mass.grams != 2000,]
positiveY = positiveY[positiveY$mass.grams != 2500,]
positiveY = positiveY[positiveY$mass.grams != 2800,]
#plot(mass.grams~analogValue, data = positiveY)
#summary(lm(mass.grams~analogValue, data = positiveY))
positiveY$direction = 'positive'
positiveY$Date = as.Date('2017-01-05')
##############################################
# Split out the Z-axis data as well. 
positiveZ = rawCal[rawCal$axis == 'Z',]
positiveZ$direction = 'positive'
positiveZ$Date = as.Date('2017-01-05')
#plot(mass.grams~analogValue, data = positiveZ)
#summary(lm(mass.grams~analogValue, data = positiveZ))
# Concatenate into one data frame
calibs = rbind(calibs, negativeX,positiveX,negativeY,positiveY,positiveZ)

par(mfrow = c(3,2))
plot(mass.grams~analogValue, data = negativeX, main = 'X, 2017-01-05')
plot(mass.grams~analogValue, data = positiveX, main = 'X, 2017-01-05')
plot(mass.grams~analogValue, data = negativeY, main = 'Y, 2017-01-05')
plot(mass.grams~analogValue, data = positiveY, main = 'Y, 2017-01-05')
plot(mass.grams~analogValue, data = positiveZ, main = 'Z, 2017-01-05')
#
```



```{r importData, cache = TRUE, echo=showcode}

if (.Platform$OS.type == 'windows'){
  fdir = "D:/Dropbox/Force Meter Files with Luke/Force Meter Data and Calibration Files/"
} else if (.Platform$OS.type == 'unix'){
  fdir = "~/Dropbox/Force Meter Files with Luke/Force Meter Data and Calibration Files/"
}

fdir = './Data/'
fnames = dir(fdir)
fnames  # print file names
# Do not bother with Apr 26 2016 data, the Z-axis wasn't working.
# The calibration data for Dec 14 2016 aren't useful because the Y-axis 
# connector was broken. 

#[1] "CalibrationFiles_Apr202016.csv"  # Use for May 2016 runs
#[2] "CalibrationFiles_Dec132016.csv"
#[3] "CalibrationFiles_Dec142016.csv"  # These values are no good for Y-axis
#[4] "CalibrationFiles_Jan42017.csv" 
#[5] "CalibrationFiles_Jan52017.csv" 
#[6] "ForceMeterData_Apr262016.csv"  
#[7] "ForceMeterData_Dec142016.csv"  
#[8] "ForceMeterData_Dec152016.csv"  
#[9] "ForceMeterData_Jan52017.csv"   
#[10] "ForceMeterData_Jan62017csv.csv"
#[11] "ForceMeterData_May182016.csv"  
#[12] "ForceMeterData_May192016.csv" 

# subset names by file type (calibration or force trials)
calibfiles = fnames[grep(x = fnames, pattern = 'Calibration')]
forcefiles = fnames[grep(x = fnames, pattern = 'ForceMeterData')]
eventFile = fnames[grep(x = fnames, pattern = 'Pound_ForceData_Final.csv')]

# Load the event file
events = read.csv(paste0(fdir,eventFile))
events$Date = as.Date(events$Date, format = '%m/%d/%Y')

# Calibration data for three of the days were put into the 'calibs' data 
# frame above. Now import the 2016-04-20 calibration data, since we only have
# the summary means for that date. 
aprFname = 'CalibrationFiles_Apr202016.csv'
temp = read.csv(paste0(fdir,aprFname))
# Extract date from file name
locs = regexpr(text = aprFname,
		pattern='[[:upper:]][[:lower:]]{2}[[:digit:]]*.csv')
month = substr(aprFname,start = locs[[1]][1], 
		stop = locs[[1]][1] + 2)
nums = regexpr(text = aprFname,
		pattern='[[:digit:]]+')
if(attr(nums,'match.length')>5){
	# 2-digit day value
	day = substr(aprFname,start = nums[[1]][1],
			stop = nums[[1]][1]+1)
	yr = substr(aprFname, start = nums[[1]][1]+2,
			stop = nums[[1]][1]+5)
} else {
	# 1- digit day value
	day = substr(aprFname,start = nums[[1]][1],
			stop = nums[[1]][1])
	yr = substr(aprFname, start = nums[[1]][1]+1,
			stop = nums[[1]][1]+4)
}
# Assemble date
temp$Date = as.Date(paste0(month,'-',day,'-',yr),format = "%b-%d-%Y")

calibs = rbind(calibs,temp)


if (exists('forces')) rm(forces)

# Concatenate all force data into one data frame
for (i in 1:length(forcefiles)){ 
	temp = read.csv(paste0(fdir,forcefiles[i]))

	# Extract date from file name
	locs = regexpr(text = forcefiles[i],
			pattern='[[:upper:]][[:lower:]]{2}[[:digit:]]*.csv')
	month = substr(forcefiles[i],start = locs[[1]][1], 
			stop = locs[[1]][1] + 2)
	nums = regexpr(text = forcefiles[i],
			pattern='[[:digit:]]+')
	if(attr(nums,'match.length')>5){
		# 2-digit day value
		day = substr(forcefiles[i],start = nums[[1]][1],
				stop = nums[[1]][1]+1)
		yr = substr(forcefiles[i], start = nums[[1]][1]+2,
				stop = nums[[1]][1]+5)
	} else {
		# 1- digit day value
		day = substr(forcefiles[i],start = nums[[1]][1],
				stop = nums[[1]][1])
		yr = substr(forcefiles[i], start = nums[[1]][1]+1,
				stop = nums[[1]][1]+4)
	}
	# Assemble date	
	thisDate = as.Date(paste0(month,'-',day,'-',yr),format = "%b-%d-%Y")
	if (thisDate == as.Date('2016-04-26')){
		# skip any file from 2016-04-26
	} else {
		# Remove columns that don't match these names:
		keepCols = c('Time.msec.','JOY_X_signal','JOY_Y_signal','BEAM_Z_signal')
		temp = temp[,keepCols]
		names(temp)[1] = 'Time.msec'
		temp$Date = thisDate
		
		if (!exists('forces')){
			forces = temp
		} else {
			forces = rbind(forces,temp)
		}
	}
	
}

# Rename the Time.msec. column to Time.msec
#names(forces)[1] = 'Time.msec' 

```

The relevant calibration file for the May 2016 trials is the Apr202016 file.

During the import process, the calibration files and force trial files are 
concatenated together into two data frames, `calibs` and `forces`, each with a
`Date` column that can be used to separate different days. The data frame
`events` contains the identified peck and push events, with dates and
millisecond timestamps. 


The goal is to go through each identified event and extract the X, Y, and 
Z-axis forces (which need to be estimated based on the associated calibration
values). The `events` data frame currently only has the net euclidean norm 
(total for all 3 axes).

```{r calibDetermination, cache = FALSE, echo=showcode}
# For each date in the 'calibs' data frame, fit regressions to each axis
# and determine conversions from raw counts to force in Newtons. 

dates = unique(calibs$Date) 

# 2016-04-20 calibration goes with May 18 + 19 2016 ForceMeterData
# 2016-12-13 calibration goes with Dec 14 + 15 2016 ForceMeterData
# 2017-01-04 calibration goes with Jan 5 2017 ForceMeterData
# 2017-01-05 calibration goes with Jan 6 2017 ForceMeterData

for (i in 1:length(dates)){
  # subset the calibs by date 
  temp = calibs[calibs$Date == dates[i],]
  
  tempCalib = calibCoefficients(temp)
  # Assemble into a list based on date
  if (i == 1){
    calibCoeffs = list()
    calibCoeffs[[1]] = tempCalib 
    calibCoeffs[[i]]$Date = dates[i]
    # names(calibCoeffs[1]) = dates[i]
  } else if (i > 1) {
    calibCoeffs[[i]] = tempCalib
    calibCoeffs[[i]]$Date = dates[i]
  }
}


for (j in 1:length(calibCoeffs)){
	if (j == 1){
		calibDates = calibCoeffs[[j]]$Date	
	} else {
		calibDates = c(calibDates,calibCoeffs[[j]]$Date)
	}
}
 
```


```{r stepThroughEvents, cache = TRUE, echo=showcode}

# Go through each event in the events data frame, pull out the relevant time
# which should be in the Time_msec column and the 
# associated Date. Then go find the relevant rows in the forces data frame
# to get the raw JOY_X_signal, JOY_Y_signal, and BEAM_Z_signal for a chunk of 
# just before and after the event. Use the relevant calibration data to convert
# each channel to forces in Newtons 
events2 = events # make a copy
events2$X.N = NA  # make empty columns
events2$Y.N = NA
events2$Z.N = NA
for (i in 1:length(events$Event)){
	dateval = events[i,'Date']
	msecval = events[i,'Time_msec']
# Go into forces and find the time point
# Start by subsetting by Date
	temp = forces[forces$Date == dateval,]
	timeMatch = which.min(abs(temp$Time.msec - msecval))
# Grab some rows ahead and after the timeMatch
	temp2 = temp[(timeMatch-100):(timeMatch+100),c('JOY_X_signal','JOY_Y_signal',
					'BEAM_Z_signal','Time.msec','Date')]
# Use the initial rows as a local zero offset reading to apply the calibration.

# 2016-04-20 calibration goes with May 18 + 19 2016 ForceMeterData
# 2016-12-13 calibration goes with Dec 14 + 15 2016 ForceMeterData
# 2017-01-04 calibration goes with Jan 5 2017 ForceMeterData
# 2017-01-05 calibration goes with Jan 6 2017 ForceMeterData

	# Use the calib file from the day before the force dateval (i.e. the
	# date closest to dateval-1)
	tempcalibs = calibCoeffs[[which.min(abs(calibDates - (dateval-1)))]]
	
	##############################################
# Convert raw count data to forces
	temp2$X.N = (temp2$JOY_X_signal * tempcalibs$X$slope) + 
			tempcalibs$X$intercept
	temp2$Y.N = (temp2$JOY_Y_signal * tempcalibs$Y$slope) + 
			tempcalibs$Y$intercept
	temp2$Z.N = (temp2$BEAM_Z_signal * tempcalibs$Z$slope) + 
			tempcalibs$Z$intercept
	##################
# Calculate an offset from 'zero' for each axis using the first few samples
# where there is presumably no force being exerted
	xoffset = mean(temp2$X.N[1:50])
	temp2$X.N = temp2$X.N - xoffset
	yoffset = mean(temp2$Y.N[1:50])
	temp2$Y.N = temp2$Y.N - yoffset
	zoffset = mean(temp2$Z.N[1:50])
	temp2$Z.N = temp2$Z.N - zoffset 
# Take the focal time match and write it into the new columns of the events2 
	# data frame.
	events2[i,'X.N'] = temp2$X.N[101]
	events2[i,'Y.N'] = temp2$Y.N[101]
	events2[i,'Z.N'] = temp2$Z.N[101]
	
# Also generate a list containing an entry for each event that will hold the
	# relevant time points
	if (i == 1){
		forceList = list()
	} 
	forceList[[i]] = temp2
	forceList[[i]]$Event = events[i,'Event'] 
	# Calculate the euclidean norm of all three axes forces
	xyz = as.matrix(forceList[[i]][,c('X.N','Y.N','Z.N')])
	for (k in 1:nrow(xyz)){
		# norm() function computes the norm. Needs to work on one row of data at
		# a time
		forceList[[i]]$Norm[k] = norm(xyz[k,],"2")	
	}
	 
}	
# Save output
# write.csv(events2,file='Pound_ForceData_withXYZ_forces.csv',row.names=FALSE)

```

```{r test, eval = FALSE, echo = FALSE}
eNum = 3
timepts = 90:120
ylims = range(forceList[[eNum]][,c("X.N","Y.N","Z.N","Norm")])
ylims[1]=floor(ylims[1])
ylims[2]=ceiling(ylims[2])
cexlab = 1.5
cexaxs = 1.5
par(mar = c(5,5.5,3,1))
showEvents = TRUE  # turn the vertical lines marking the event(s) on or off
# Generate base plot
plot(x = forceList[[eNum]]$Time.msec[timepts],forceList[[eNum]]$X.N[timepts], 
		type = 'b', col = 'orange', ylim = ylims, 
		xlab = 'Elapsed time, milliseconds',
		ylab = 'Force, N', las = 1, cex.axis = cexaxs, 
		cex.lab = cexlab)
rect(par()$usr[1],par()$usr[3],par()$usr[2],par()$usr[4],col='grey90')
grid(col='white',lty = 2)
abline(h= 0, lty = 2, col = 'black')
if(showEvents){
# Add a vertical line at the event time, which should be entry 101 if we 
# extracted the 100 time points before and after each event's Time.msec value
abline(v = forceList[[eNum]]$Time.msec[101])
# Also plot a marker for the next event, and if it shows up in the plot, it 
# may indicate that the two events are too close together
abline(v = forceList[[eNum+1]]$Time.msec[101], lty = 2)
}
# Plot the individual force traces
lines(x = forceList[[eNum]]$Time.msec[timepts],
		forceList[[eNum]]$X.N[timepts], col = 'forestgreen')
points(x = forceList[[eNum]]$Time.msec[timepts],
		forceList[[eNum]]$X.N[timepts], col = 'forestgreen', pch = 20, cex = .75)
lines(x = forceList[[eNum]]$Time.msec[timepts],
		forceList[[eNum]]$Y.N[timepts], col = 'blue')
points(x = forceList[[eNum]]$Time.msec[timepts],
		forceList[[eNum]]$Y.N[timepts], col = 'blue', pch = 20, cex = .75)
lines(x = forceList[[eNum]]$Time.msec[timepts],
		forceList[[eNum]]$Z.N[timepts], col = 'red')
points(x = forceList[[eNum]]$Time.msec[timepts],
		forceList[[eNum]]$Z.N[timepts], col = 'red', pch = 20, cex = .75)
# Plot the norm
lines(x = forceList[[eNum]]$Time.msec[timepts],
		forceList[[eNum]]$Norm[timepts],col='orange')
mtext(side = 3, text = paste0('Event ',forceList[[eNum]]$Event,", ",
				forceList[[eNum]]$Date[1]), line = 1,
		cex = 2)
legend('topleft', legend = c('X','Y','Z','Norm (Net Force)'),
		col = c('forestgreen','blue','red','orange'), lwd = 2, bty = 'n')
######################################################################
mean(forces$JOY_Y_signal[forces$Date == as.Date('2016-12-15')])
mean(forces$BEAM_Z_signal[forces$Date == as.Date('2016-12-15')])

# Plot the raw 2016-12-15 data
mydate = as.Date('2016-12-14')
plot(JOY_X_signal~Time.msec, 
		data = forces[forces$Date == mydate,],
		type = 'l', ylim = c(1800,2700))
lines(JOY_Y_signal~Time.msec, 
		data = forces[forces$Date == mydate,],
		col = 'red')
lines(BEAM_Z_signal~Time.msec, 
		data = forces[forces$Date == mydate,],
		col = 'forestgreen')

######################################################################


```

## DEFINTIONS

These definitions are based on Rachel's email from 2018-02-06.

* A given force can only be assigned to one category (cannot be a push *and*
  peck)
* Forces discussed below refer to net Euclidean forces in 3 dimensions
  (`norm`).

### Peck:

* Peak magnitude: ≥ 2 N, and MUST BE greater than or equal to two times the
magnitude of the force data points immediately before AND after a given point. 
* Duration: Force > 2 N MUST BE sustained for ≤ 2 successive samples, giving
a total event duration of less than 30 ms. 
* Both the magnitude and duration conditions must be met in order for a force
to be categorized as a Peck

### Push:

* Peak magnitude: ≥ 2 N, and may or may not be greater than or equal to two
  times the magnitude of the force before and after a given force data point
* Duration:  Forces ≥ 2 N that do not meet the magnitude criteria for a 
  Peck may be sustained for any amount of time
* Forces categorized as Pushes do not meet conditions of Peck and Touch

### Touch:

* Magnitude: < 2 N  (e.g. the bird seems to be playing with the ‘limpet’
mimic rather than actively attempting to remove it)
* We are not considering ‘Touches’ in our force meter analyses


Additional clarification, from Rachel in email on 2018-02-06:
"Secondly, had event #3 been an actual force produced by the bird, we did
classify these events as a peck because had considered a peck to be a force that
was exerted over one or two sampling intervals.  We did this because there were
instances when the bird produced two forces in quick succession that created a
distinct force peak on the read outs (such as in your
Limpet_force_meter_analysis, figure 2016-12-14, 621.47s, push).  In this case,
we classified both of the peaks in that example as pecks because, when the
forces were lumped together,  the magnitude of the first and second forces were
twice the magnitude of the forces before or after it (presumably in this case
those forces were 0 N).  So even though those two forces are not distinct peaks,
in an example like this, we lumped them together as one peak."

  
## Picking pecks and pushes

I wrote an interactive function (`PushPeckPickFunction()`) to let the user pick a 
trial date and 
go through the raw time series data and attempt to identify potential pecks and
pushes. The script has the user first identify a period of at least 8 samples 
(80 milliseconds) where the baseline signal appears stable, and then the user
clicks on each peak above the 2N threshold outlined above. Because the sensors
tended to drift and take new baseline values, particularly after big hits by
the bird, the user is identifying a new baseline for each peak or group of
peaks that happen in quick succession and appear to share a common baseline
value. The output of the function `peakChooser()` is a data frame that contains
a row from the original `forces` data frame for each identified peak. As a
result, the time in milliseconds (`Time.msec`), the raw X, Y, Z values
(`X.N`,`Y.N`,`Z.N`, units of Newtons), calibrated forces in the X, Y, and Z axes
(`X.N.off`, `Y.N.off`,`Z.N.off`, units of Newtons), the
euclidean norm of all 3 axes (`Norm`, units of Newtons), and the time stamp of
the chosen baseline value (`BaselineTime.msec`) are available for each peak
event. These data could be
used to relocate a chunk of the raw time series around each peak event for
further analysis. 



```{r PushPeckPickFunction, eval = FALSE, echo=showcode}

# Code to run through a data set and have the user identify probable push or 
# peck events. 
# All raw data are in the 'forces' data frame

# Step through rows of 'forces' data frame, plot a chunk of time vs Norm, and
# have user select any events that look like pecks or pushes.  

# Since 'forces' data frame only has raw signals, we need to apply the 
# calibration values to each chunk of data to convert to Newtons and calculate
# the norm. 

# The code here is shown for reference, but not evaluated in this document
# because it requires user interaction. This code was used to produce the 
# data in the events file 'Events_picker_output_20180213.csv' used elsewhere in this
# document.


library(RANN) # for nn2 nearest neighbor search function

#' Peck/Push event chooser
#' 
#' @param trialDate  - A Date object giving the date of the bird trial
#' @param forces - a dataframe containing all of the trial data from each day, imported
#' earlier
#' @param calibs - a list object containing the calibration slopes associated from 
#' each trial date. Created earlier.
#' @param eventsdf - an optional data frame created from the output of this function. If
#' supplied, this will be used to plot markers on already-identified peaks in the
#' chosen day's timeseries. 
#' @param baseLength - the number of samples to be averaged together to form the baseline
#' values for X, Y, and Z axes prior to an identified peak. 8 samples at 10ms 
#' interval = 80 milliseconds
#' 
#' @return A data frame containing an entry for each identified peak events,
#' with columns Time.msec, JOY_X_signal, JOY_Y_signal, BEAM_Z_signal,
#' Date, X.N (raw X axis force in Newtons), Y.N (raw Y-axis force), Z.N (raw
#' Z-axis force), X.N.off (the estimated actual X-axis force in Newtons, 
#' after accounting for baseline drift), Y.N.off, Z.N.off, Norm (net force
#' for all 3 axes (X, Y, Z) after accounting for baseline drift, in Newtons)
#' and BaselineTime.msec (timestamp for the chosen baseline samples for this
#' peak.
	
peakChooser = function(trialDate, forces = forces, calibs = calibCoeffs, 
		eventsdf = NULL, baseLength=8){
	require(RANN)
	if (!is.null(eventsdf)){
		peakPushEvents = eventsdf
	}
	
	# Extract force data for the current date
#	dat = forces[forces$Date == myDates[dayDate],]
	dat = forces[forces$Date == trialDate,]
	nsamps = nrow(dat)
	
	baseLength = baseLength - 1 # take off 1 since we always add to baseLocation
	# Get the relevant calibration data from calibCoeffs list

	
#	tempcalibs = calibCoeffs[[which.min(abs(calibDates-(myDates[dayDate]-1)))]]
	tempcalibs = calibCoeffs[[which.min(abs(calibDates-(trialDate-1)))]]
	
	# Generate estimates of force (N) on each axis using the calibration data. 
	# Note however that these force values will have an offset due to the drift
	# in the baseline value of the transducers. So for each chosen peak, we will
	# first identify a preceding baseline set of "0" values and correct these
	# force values by that baseline offset. 
	dat$X.N = (dat$JOY_X_signal * tempcalibs$X$slope) + 
			tempcalibs$X$intercept
	dat$Y.N = (dat$JOY_Y_signal * tempcalibs$Y$slope) + 
			tempcalibs$Y$intercept
	dat$Z.N = (dat$BEAM_Z_signal * tempcalibs$Z$slope) + 
			tempcalibs$Z$intercept

	# Make a plot of raw sample data to have user select a baseline time period
	repeatLoop = TRUE
	for (j in seq(1,nsamps, by = 1000)){
		while(repeatLoop == TRUE){
			# Create the initial wide-angle plot showing 1000 samples
			# Calculate an offset for JOY_Y signal so that it's close to 
			# JOY_X data on the y-axis for plotting purposes 
			offY = (dat[1,'JOY_X_signal']-dat[1,'JOY_Y_signal'])
			ylims = range(dat[,'JOY_X_signal'])
			plot(dat$Time.msec[j:(j+999)],y = dat[j:(j+999),'JOY_X_signal'],
					type='l',
					ylim = ylims, xlab = 'Time, ms', yaxs='i', 
					ylab = paste0('Raw axis signal'), 
					main = trialDate)
			# Add the offset Y-axis values to the plot
			lines(x = dat$Time.msec[j:(j+999)],
					y = dat[j:(j+999),'JOY_Y_signal']+offY,
					col = 'blue')
			# Check and see if peakPushEvents data frame exists
			if (exists('peakPushEvents')){
				# If it exists, find any events that might already be 
				# identified in the current plot
				peakPushSub = peakPushEvents[which(peakPushEvents$Date == 
										unique(dat$Date)),]
				# Subset only rows that are within the current time range
				peakPushSub = peakPushSub[which( (peakPushSub$Time.msec > 
										dat$Time.msec[j]) & 
								(peakPushSub$Time.msec < 
									dat$Time.msec[j+999])),]
				# Plot previously identified peaks on the current plot
				points(x=peakPushSub$Time.msec, 
						y = peakPushSub[,'JOY_X_signal'],
						pch = 20, col = 'red')
				# Plot previously identified peaks on the current plot
				points(x=peakPushSub$Time.msec, 
						y = peakPushSub[,'JOY_Y_signal']+offY,
						pch = 20, col = 'skyblue')
			}
			par(xpd = TRUE)
			# Draw button for skipping ahead to next section
			dist = (par()$usr[2]-par()$usr[1]) * 0.2
			bluelocsx = c(par()$usr[2]-dist, par()$usr[2],par()$usr[2],
					par()$usr[2]-dist)
			bluelocsy = c(ylims[2],ylims[2],ylims[2]+100,ylims[2]+100)
			polygon(bluelocsx,bluelocsy,col='lightblue')
			text(x = par()$usr[2],y = par()$usr[4], labels='skip ahead',
					adj = c(1.5,-1.5))
			# Put message on plot
			text(x = par()$usr[1], y = ylims[2],
					labels = 'Click on peak to zoom in\n or click blue button\n to skip ahead',
					adj = c(0,-0.5))
			# Have the user choose either a button or peak to zoom in on
			clickLocation = locator(n = 1)
			# Handle the click
			if (clickLocation$x > bluelocsx[1] & 
					clickLocation$x < bluelocsx[2] &
					clickLocation$y > bluelocsy[1] & 
					clickLocation$y < bluelocsy[3]) {
				# User clicked in the skip ahead box
				print("skip ahead")
				skip = TRUE
				zoom = FALSE
			} else if (clickLocation$x > par()$usr[1] &
					clickLocation$x < par()$usr[2] & 
					clickLocation$y > par()$usr[3] & 
					clickLocation$y < par()$usr[4]) {
				# User clicked somewhere else in the figure, decide if it was 
				# a value location to click
				print('click in plot')
				points(x = clickLocation$x, y = clickLocation$y, col = 'red',
						pch = 20, cex = 1.5)
				zoom = TRUE
				skip = FALSE
			} else {
				# User clicked outside the plot or buttons, so trigger a re-plot
				print('click not in field')
				clickLocation
				zoom = FALSE
				skip = FALSE 			
			}
				
			if (zoom == FALSE & skip == TRUE){
				# cycle main loop again to move to next chunk of time			
				break  # break out of while loop
			} else if (zoom == TRUE & skip == FALSE) { 
				##################################################
				# Create the 2nd plot (the initial zoomed-in plot)
				# Zoom in for the next phase of peak choosing
				# Find the row of dat closest to the click location
				clickRow = which.min(abs(clickLocation$x - dat$Time.msec))
				# subset a new data frame centered around the clickRow
			    temp = dat[(clickRow-100):(clickRow+100),]
	
				# Now the user will choose a time point that represents the
				# baseline force value for upcoming peaks
				ylims = range(c(temp[,'JOY_X_signal'],
								temp[,'JOY_Y_signal']+offY))
				xlims = range(temp$Time.msec)
				plot(temp$Time.msec,
						y = temp[,'JOY_X_signal'],
						type = 'l', 
						ylab = paste0('Raw axis signal'), 
						xlab = 'Time, ms',
						ylim = ylims)
				lines(temp$Time.msec,
						y = temp[,'JOY_Y_signal']+offY, col = 'blue')
				points(temp$Time.msec,
						y = temp[,'JOY_X_signal'], col = 'black',
						pch = 20, cex = 0.8)
				points(temp$Time.msec,
						y = temp[,'JOY_Y_signal']+offY, col = 'blue',
						pch = 20, cex = 0.8)
				if (exists('peakPushEvents')){
					# If it exists, find any events that might already be 
					# identified in the current plot
					peakPushSub = peakPushEvents[which(peakPushEvents$Date == 
											unique(dat$Date)),]
					# Subset only rows that are within the current time range
					peakPushSub = peakPushSub[which( (peakPushSub$Time.msec > 
												temp$Time.msec[1]) & 
											(peakPushSub$Time.msec < 
												temp$Time.msec[nrow(temp)])),]
					# Plot previously identified peaks on the current plot
					points(x=peakPushSub$Time.msec, 
							y = peakPushSub[,'JOY_X_signal'],
							pch = 20, col = 'red')
					points(x=peakPushSub$Time.msec, 
							y = peakPushSub[,'JOY_Y_signal']+offY,
							pch = 20, col = 'magenta')
				}
				par(xpd=TRUE)
				# Plot a button for user to skip ahead
				dist = (par()$usr[2]-par()$usr[1]) * 0.2
				bluelocsx = c(par()$usr[2]-dist, par()$usr[2],par()$usr[2],
						par()$usr[2]-dist)
				bluelocsy = c(par()$usr[4],par()$usr[4],ylims[2]+100,ylims[2]+100)
				polygon(bluelocsx,bluelocsy,col='lightblue')
				text(x = par()$usr[2],y = par()$usr[4], 
						labels='Skip to next section', adj = c(-0.1,-1))
				text(x=par()$usr[1], y = par()$usr[4],
						labels='Click a baseline point or hit skip', 
						adj = c(0,-0.3))
				# The user should click on a baseline point now. 
				clickLocation = locator(n = 1)
				if (clickLocation$x > bluelocsx[1] & 
						clickLocation$x < bluelocsx[2] &
						clickLocation$y > bluelocsy[1] & 
						clickLocation$y < bluelocsy[3]) {
					# User clicked in box to skip ahead
					# Set zoom and skip so that the wide-angle plot will still
					# show the same range of time as the previous wide plot
					zoom = FALSE
					skip = FALSE
					break
				} else if (clickLocation$x > par()$usr[1] &
						clickLocation$x < par()$usr[2] & 
						clickLocation$y > par()$usr[3] & 
						clickLocation$y < par()$usr[4]) {
					# User clicked on baseline plot, find nearest row
					baseLocRow = which.min(abs(clickLocation$x - 
											temp$Time.msec))
					# Use the chosen row value to work out a baseline value
					# to use with the calibrations
				}
				
				##########################
				# With a baseline location in hand, calculate calibrated force
				# values and replot the norm'd forces
				# Calculate an offset from 'zero' for each axis using the first 
				# few samples where there is presumably no force being exerted
				xoffset = mean(temp$X.N[baseLocRow:(baseLocRow+baseLength)])
				temp$X.N.off = temp$X.N - xoffset
				yoffset = mean(temp$Y.N[baseLocRow:(baseLocRow+baseLength)])
				temp$Y.N.off = temp$Y.N - yoffset
				zoffset = mean(temp$Z.N[baseLocRow:(baseLocRow+baseLength)])
				temp$Z.N.off = temp$Z.N - zoffset 
				# Calculate euclidean norm force
				for (r in 1:nrow(temp)){
					xyz = as.matrix(temp[r,c('X.N.off','Y.N.off','Z.N.off')])
					temp$Norm[r] = norm(xyz,'2')
				}
				################################################################
				# Create the 3rd plot, showing Norm'd force
				# Have user identify peaks here to be classified as peak/push
				xlims = range(temp$Time.msec)
				ylims = range(temp$Norm)
				plot(x = temp$Time.msec, y = temp$Norm,type='b', 
						xlab = 'Time, msec', ylab = 'Norm, Newtons', las = 1)
				if (exists('peakPushEvents')){
					# If it exists, find any events that might already be 
					# identified in the current plot
					peakPushSub = peakPushEvents[which(peakPushEvents$Date == 
											unique(dat$Date)),]
					# Subset only rows that are within the current time range
					peakPushSub = peakPushSub[which( (peakPushSub$Time.msec > 
												temp$Time.msec[1]) & 
											(peakPushSub$Time.msec < 
												temp$Time.msec[nrow(temp)])),]
					# Plot previously identified peaks on the current plot
					points(x=peakPushSub$Time.msec, y = peakPushSub$Norm,
							pch = 20, col = 'red')
				}
				# Plot the chosen baseline points
				points(x = temp$Time.msec[baseLocRow:(baseLocRow+baseLength)], 
						y = temp$Norm[baseLocRow:(baseLocRow+baseLength)], 
						pch = 20, col = 'orange')
				text(x = temp$Time.msec[baseLocRow], 
						y = temp$Norm[baseLocRow]+1, labels = 'Baseline',
						adj=c(0,0.7))
				par(xpd=FALSE)
				grid(col = 'grey70',lty = 2)
				abline(h = 2, lty = 2, col = 'red')
				par(xpd=TRUE)
				# Add a box to let the user declare they are done choosing
				dist = (par()$usr[2]-par()$usr[1]) * 0.2
				bluelocsx = c(par()$usr[2]-dist, par()$usr[2],par()$usr[2],
						par()$usr[2]-dist)
				bluelocsy = c(par()$usr[4],par()$usr[4],ylims[2]+100,ylims[2]+100)
				polygon(bluelocsx,bluelocsy,col='lightblue')
				text(x = par()$usr[2],y = par()$usr[4], 
						labels='Done choosing', adj = c(1.3,-1))
				text(x = par()$usr[1],y = par()$usr[4], 
						labels = 'Click on each peak',
								adj = c(0,-0.5))
				keepChoosing = TRUE
				while(keepChoosing == TRUE){
					clickLocation = locator(n = 1) # have user select a point
					# Draw where the user clicked
					points(x=clickLocation$x,y=clickLocation$y,col='blue',
							pch = 20)
					if (clickLocation$x > bluelocsx[1] & 
							clickLocation$x < bluelocsx[2] &
							clickLocation$y > bluelocsy[1] & 
							clickLocation$y < bluelocsy[3]) {
						# User clicked in box to say they are done choosing
						break  # kill the while(keepChoosing == TRUE) loop
					} else if (clickLocation$x > par()$usr[1] &
							clickLocation$x < par()$usr[2] & 
							clickLocation$y > par()$usr[3] & 
							clickLocation$y < par()$usr[4]) {
						# User clicked on plot, find nearest point
						# by using a nearest neighbor search algorithm using
						# the function nn2 from the package 'RANN'
						# Prepare the data matrix
						mymatrix = cbind(temp$Time.msec,temp$Norm)
						# Rescale the x-axis data, since the results of nn2
						# will be thrown off if the scale of x data is very 
						# different from the scale of y data
						mymatrix[,1] = mymatrix[,1]/1000
						mypoint = cbind(clickLocation$x,clickLocation$y)
						# Also rescale the clickLocation x-axis value
						mypoint[,1] = mypoint[,1]/1000
						# Run the nearest neighbor search. The k=1 argument
						# should return the 1st-closest nearest neighbor
						rowIndex = RANN::nn2(data=mymatrix,query=mypoint,
								k = 1)$nn.idx[1,1]
						# Add the identified point to the plot
						points(temp$Time.msec[rowIndex],y=temp$Norm[rowIndex],
								pch = 20, col = 'royalblue')
						# Use the chosen row value to work out a baseline value
						# to use with the calibrations
						keepChoosing = TRUE
						if(!(exists('peakPushEvents'))){
							# Get the appropriate row of info out of the
							# original data frame dat
							peakPushEvents = temp[rowIndex,]
							# Also add on the Time.msec value for the baseline
							# point
						    peakPushEvents$BaselineTime.msec = temp$Time.msec[baseLocRow]
						} else {
							# If peakPushEvents exists, add onto it
							tempVals = temp[rowIndex,] # extract the peak row
							# Add on the baseline row Time.msec value
							tempVals$BaselineTime.msec = temp$Time.msec[baseLocRow]
							# rbind the new data onto peakPushEvents
							peakPushEvents = rbind(peakPushEvents,
									tempVals)
						}
						keepChoosing = TRUE # allow while loop to repeat
					} # end of if (clickLocation$x > bluelocsx[1]... section
				} # end of while(keepChoosing == TRUE)

			} else if (zoom == FALSE & skip == FALSE ){
				# let the main plot loop repeat (plots a wide-angle view)
				repeatLoop = TRUE 
			}
		} # end of while(repeatLoop == TRUE) 
	}
	cat('Finished\n')
	# Return peakPushEvents data frame
	peakPushEvents
	
} # end of function

```

```{r choosePeaks, eval = FALSE, echo=TRUE}
# After defining the peak choosing function in the previous chunk of code, 
# now use it to identify potential peak/push events on each trial date. 
# Run the code in this chunk manually, since it requires a lot of user 
# interaction. 

# This chunk is provided for reference but not evaluated in this Rmd document.
# The results from this code were stored as the events in the
# file 'Events_picker_output_20180213.csv'

# Available trial dates:
# 2016-05-18
# 2016-05-19
# 2016-12-14
# 2016-12-15  
# 2017-01-05 
# 2017-01-06

mydate = as.Date('2017-01-06')

eventdf = peakChooser(trialDate = mydate, forces = forces, calibs = calibCoeffs,
		eventsdf = NULL, baseLength = 8)

# events20160518 = eventdf
# events20160519 = eventdf
# events20161214 = eventdf
# events20161215 = eventdf
# events20170105 = eventdf
# events20170106 = eventdf
 output = rbind(events20161214,events20161215,events20160518,
 			events20160519,events20170105,events20170106)
#
output[,6:12] = round(output[,6:12], digits = 2)
output= cbind(seq(1,nrow(output)),output)
names(output)[1]= 'EventNumber'
write.csv(output, file = './Data/Events_picker_output_20180213.csv',row.names=FALSE)

```

# Classifying peaks vs. pushes

The output from the `peakChooser()` function was saved to a csv file called
`Events_picker_output_20180213.csv`. The data in that file next need to be 
processed to determine if each event was a peck or a push according to the 
criteria outlined above. 

```{r classifyPeckPushFunction, echo=showcode}

#################################
# Function peckPushAlgo
#' Classify an event as a peck or push 
#' 
#' Classify each event as a peck or push based on the defined criteria. For a
#' peck, the peak force must be more than 2x larger than the force immediately
#' before and after the peak force. In addition, a peak must have the force
#' be above the forceThreshold value (usually 2 N) for no more than 2 sample
#' intervals. Based on these rules, a peck will have a duration of either 20 ms
#' or 30 ms (one sample above threshold or 2 samples above threshold, 
#' respectively). Cases where the >2N forces go on for longer than 30ms
#' will be defined as a push regardless of the 2x-larger threshold defined above. 
#' 
#' @param Norm A vector of forces (euclidean norm = 3-axis net force), units of 
#' Newtons 
#' @param peakIndex A row index into the Norm vector that marks the peak to be
#' classified as a Peck or Push
#' @param forceThreshold Numeric value specifying the minimum force (Newtons) 
#' needed for the peak to be considered a Peck or Push. Default = 2 Newtons. 
#' @param forceRatio Numeric values specifying the minimum ratio of forces
#' between the peak force and samples immediately before and after the peak
#' force, for classification as a Peck vs. a Push. Default = 2. 
#' @return A 1-element character vector containing 'Peak', 'Push', or NA, based
#' on the results of the classification algorithm. 

peckPushAlgo <- function(Norm, peakIndex, forceThreshold = 2, forceRatio = 2){
# Determine if this event can be a peck
	
	# Start by getting the smaller forces immediately before and after
	# the peakIndex force
	nearestBefore = Norm[peakIndex-1]
	nearestAfter = Norm[peakIndex+1]
	# The test for classifying a Peck involves the peak force being 2x larger
	# than the two nearest neighboring forces. BUT, in specific cases where
	# there are 2 large forces in a row >2N, we instead check that the larger of 
	# the pair of forces is 2x larger than the nearest
	# neighbors before and after that pair of points.
	
	before1Flag <- before2Flag <- after1Flag <- after2Flag <- FALSE
	
	# Process the point ahead of the peak
	if ( ((Norm[peakIndex] / nearestBefore) > forceRatio) ){
		# If the ratio for the point immediately before is > forceRatio, set
		# the flags
		before1Flag = TRUE
		before2Flag = FALSE
	} else {
		# If the ratio for the 1st point before is not 2x, check the next
		# earlier point
		nearestBefore = Norm[peakIndex-2]
	
		if  ( (Norm[peakIndex] / nearestBefore) > forceRatio ){
			# If the point 2 steps ahead is 2x, set the flags
			before1Flag = FALSE
			before2Flag = TRUE
		} else {
			# In this case, both points ahead of the peak were not 2x
			before1Flag = FALSE
			before2Flag = FALSE
		}
	}
	# Now process the point after the peak
	if ( (Norm[peakIndex] / nearestAfter) > forceRatio) {
		# If the first point after meets the 2x ratio, set flags
		after1Flag = TRUE
		after2Flag = FALSE
	} else {
		# If the first point after doesn't meet the 2x ratio, check the next
		# point
		nearestAfter = Norm[peakIndex+2]
		if ( (Norm[peakIndex] / nearestAfter) > forceRatio){
			# If true, set flags
			after1Flag = FALSE
			after2Flag = TRUE
		} else {
			# If the 2nd point after wasn't 2x, then set flags
			after1Flag = FALSE
			after2Flag = FALSE
		}
	}
	
	# Now process the flags to decide if this event meets the Peck threshold
	if (before1Flag & after1Flag){
		# Points immediately before & after peak meet the 2x threshold
		peckThreshMagnitude = TRUE
	} else if (before2Flag & after1Flag){
		# A 2-point peak, where the point 2 steps ahead and 1 step after meet
		# the 2x threshold
		peckThreshMagnitude = TRUE
	} else if (before1Flag & after2Flag){
		# A 2-point peak, where the point 1 step ahead and 2 steps after meet
		# the 2x threshold
		peckThreshMagnitude = TRUE
	} else if (before2Flag & after2Flag){
		# If before2Flag and after2Flag both came up true, then the event
		# didn't meet the peck threshold
		peckThreshMagnitude = FALSE
	} else {
		# In all other cases, the event didn't meet the peck threshold because
	# the points just before and after the 1 or 2-sample peak weren't above the
	# 2x threshold
		peckThreshMagnitude = FALSE
	}

	#########################################################################
	# Now deal with the criterion that if more than 1 neighboring time point
	# is still above the forceThreshold, then this is a push. But if 0 or 1
	# neighboring time points are above forceThreshold, then this is a peck.
	highCount = 0 # Add 1 for each time a neighboring point is above threshold
	if (Norm[peakIndex-1] < forceThreshold){
		# In this case, the point immediately before peakIndex is below
		# the threshold. Keep highCount at 0
		highCount = highCount + 0
	} else { # If the point before peakIndex was > forceThreshold
		highCount = highCount + 1 # increment for one high time point neighbor
		if (Norm[peakIndex-2] < forceThreshold){
			highCount = highCount + 0 # do not increment 
		} else {
			highCount = highCount + 1 # increment
			# At this point, the high forces would be longer than the 
			# defined interval for a 'peck', so this event would be classified
			# as a push even if the 2nd and 3rd points fell below the 2x forceRatio
			# that would otherwise make this a peck.
		}
	}
	# Check the 2 time points after peakIndex now
	if (Norm[peakIndex+1] < forceThreshold){
		# In this case, the point immediately after peakIndex is already low
		highCount = highCount + 0  # do not increment in this case
	} else { # If the point after peakIndex was > forceThreshold
		highCount = highCount + 1 # increment for one high neighbor point
		# Check the 2nd time point after peakIndex
		if (Norm[peakIndex+2] < forceThreshold){
			highCount = highCount + 0 # do not increment again
		} else { # 2nd time point was also above forceThreshold
			highCount = highCount + 1 # increment
			# At this point, the high forces would be longer than the 
			# defined interval for a 'peck', so this event would be classified
			# as a push even if the 2nd and 3rd points fell below the 2x forceRatio
			# that would otherwise make this a peck.
		}
	}
	
	# Now deal with the various flags to classify as a Peck or Push
	if (peckThreshMagnitude == TRUE){
		# If peckThreshMagnitude is true, then the peak was 2x larger than
		# its largest neighbors. Now check if the high force went on for 
		# more than 2 sample intervals (20ms), including the peak time point
		if (highCount > 1) {
			# If highCount is greater than 1, then the force was high for at 
			# least 3 consecutive time points, making it a Push
			peckPush = 'Push'
		} else if (highCount <= 1){
			# If highCount is 0 or 1, the force was only high for 1 or 2 
			# sample intervals, making it a Peck. 
			peckPush = 'Peck'
		}
	} else if (peckThreshMagnitude != TRUE) {
		# If the peckThreshMagnitude is not TRUE, this may still be a series
		# of high forces above the 2N threshold, constituting a Push
		if (Norm[peakIndex] > forceThreshold){
			peckPush = 'Push'
		} else {
			# In this case the peak wasn't high enough to meet the 2x ratio
			# threshold, and also didn't go above 2N, so it should remain NA
			# to denote a Touch
			peckPush = NA
		}
	}

	peckPush  # return peck/push status
}


################################################################################
# Go through each row in events2, and pull the relevant data from the 
# forces data frame to generate a plot of the time just before and after an 
# identified peak

#' A function to go through all events and classify them as pecks or pushes
#' @param events A data frame where each row represents an identified peak that
#'  needs to be classified as a peck or push. Contains columns 'Date', 
#'  'BaselineTime.msec', and 'Time.msec'.
#' @param forces A data frame containing raw timeseries of transducer values
#' @param calibs A list containing calibration data for each X, Y, Z transducer
#'  axis for each date. 
#' @param forceThreshold A numeric value denoting the minimum force necessary to 
#' be classified as a peck or push event (anything below this threshold is 
#' classified NA). 
#' @param baseLength A numeric value denoting the number of samples from the 
#' baseline timepoint to average for the calculation of the baseline force 
#' offset. 
#' @return A version of the input 'events' data frame with a column 'PeckPush'
#'  containing a classification for each event (row). 

peckpushClassify <- function(events, forces, calibs, forceThreshold = 2, 
		baseLength = 8){
	# Extract the calibration dates
	for (j in 1:length(calibCoeffs)){ 
		if (j == 1){
			calibDates = calibCoeffs[[j]]$Date	
		} else {
			calibDates = c(calibDates,calibCoeffs[[j]]$Date)
		}
	}
	# Step through each row of 'events' data frame to classify the event
	# as a peck or push
	for (i in 1:nrow(events)){
		# Get date and time for this event
		trialDate = events$Date[i]
		basetime = events$BaselineTime.msec[i]
		peaktime = events$Time.msec[i]
		# Get the relevant calibration coefficients
		tempcalibs = calibCoeffs[[which.min(abs(calibDates-(trialDate-1)))]]
		# Get data from the forces data frame starting at basetime and extending
		# past peaktime
		temp = forces[forces$Date == trialDate,]
		# Grab the relevant chunk of data
		chunk = temp[ (temp$Time.msec >= basetime) & 
						(temp$Time.msec < (peaktime+1000)),]
		peakIndex = which.min(abs(chunk$Time.msec - peaktime))
		# Convert to force, Newtons
		chunk$X.N = (chunk$JOY_X_signal * tempcalibs$X$slope) + 
				tempcalibs$X$intercept
		chunk$Y.N = (chunk$JOY_Y_signal * tempcalibs$Y$slope) + 
				tempcalibs$Y$intercept
		chunk$Z.N = (chunk$BEAM_Z_signal * tempcalibs$Z$slope) + 
				tempcalibs$Z$intercept
		# Apply offset based on the average of the baseline values (8 samples)
		xoffset = mean(chunk$X.N[1:baseLength])
		# Subtract off the offset value. If the baseline force value is negative to 
		# begin with for this section, the xoffset value will be negative, 
		# and so you end up adding the offset to all the X.N values because of
		# the X.N - (negative offset) operation. Or if the offset is positive,
		# the forces will get the offset subtracted off them. 
		chunk$X.N.off = chunk$X.N - xoffset
		yoffset = mean(chunk$Y.N[1:baseLength])
		chunk$Y.N.off = chunk$Y.N - yoffset
		zoffset = mean(chunk$Z.N[1:baseLength])
		chunk$Z.N.off = chunk$Z.N - zoffset 
		# Calculate euclidean norm force
		for (r in 1:nrow(chunk)){
			xyz = as.matrix(chunk[r,c('X.N.off','Y.N.off','Z.N.off')])
			chunk$Norm[r] = norm(xyz,'2')
		}
		# Call the peckPushAlgo() function to classify the event
		events$PeckPush[i] = peckPushAlgo(chunk$Norm, peakIndex = peakIndex,
				forceThreshold = forceThreshold, forceRatio = 2)
		
		# Estimate the duration of the event (time with force above 2N thresh)
	    # A single sample peak above the peakThreshold will end up with a 
	# minimum duration of 20 milliseconds, since that is the interval between
	# two successive sample intervals 
	# (i.e. going from 0N to >2N back to 0N  = at least 20 ms, when the sample
# interval was 10 ms. )
	    if (!is.na(events$PeckPush[i])){
			stillHigh = TRUE
			move = 1
			duration = 0
			# Check values before peak
			while (stillHigh){
				if( (chunk$Norm[peakIndex-move] > peakThreshold) ){
					duration = duration + 10
					move = move + 1
				} else {
					duration = duration + 10 # add 10 ms for sample interval
					startIndex = peakIndex-move # start index of this event
					break
				}		
			}
			move = 1 # reset for next check
			# Check values after peak
			while (stillHigh){
				if( (chunk$Norm[peakIndex+move] > peakThreshold) ){
					duration = duration + 10
					move = move + 1
				} else {
					duration = duration + 10 # add 10 ms for last sample interval
					endIndex = peakIndex+move # end index of this event
					break
				}
			}
			# Write results to columns in output data frame
			events$Duration.msec[i] = duration
			events$StartPeak.msec[i] = chunk$Time.msec[startIndex]
			events$EndPeak.msec[i] = chunk$Time.msec[endIndex]
		} else {
			# If the event was not a peck or push (was NA instead)
			events$Duration.msec[i] = NA
			events$StartPeak.msec[i] = NA
			events$EndPeak.msec[i] = NA
		}
	} 
	events # return the events data frame as output
}


# Function to plot a given event
plotpeckpush = function(eventNum, events = events2, forces=forces, 
		calibs = calibCoeffs, forceThreshold = 2,
		baseLength = 8){
	for (j in 1:length(calibCoeffs)){
		if (j == 1){
			calibDates = calibCoeffs[[j]]$Date	
		} else {
			calibDates = c(calibDates,calibCoeffs[[j]]$Date)
		}
	}
	
	i = eventNum
	# Get date and time for this event
	trialDate = events$Date[i]
	basetime = events$BaselineTime.msec[i]
	peaktime = events$Time.msec[i]
	# Get the relevant calibration coefficients
	tempcalibs = calibCoeffs[[which.min(abs(calibDates-(trialDate-1)))]]
	# Get data from the forces data frame starting at basetime and extending
	# past peaktime
	temp = forces[forces$Date == trialDate,]
	# Grab the relevant chunk of data
	chunk = temp[ (temp$Time.msec >= basetime) & 
					(temp$Time.msec < (peaktime+460)),]
	peakIndex = which.min(abs(chunk$Time.msec - peaktime))
	# Convert to force, Newtons
	chunk$X.N = (chunk$JOY_X_signal * tempcalibs$X$slope) + 
			tempcalibs$X$intercept
	chunk$Y.N = (chunk$JOY_Y_signal * tempcalibs$Y$slope) + 
			tempcalibs$Y$intercept
	chunk$Z.N = (chunk$BEAM_Z_signal * tempcalibs$Z$slope) + 
			tempcalibs$Z$intercept
	# Apply offset based on the average of the baseline values (10 samples)
	xoffset = mean(chunk$X.N[1:10])
	chunk$X.N.off = chunk$X.N - xoffset
	yoffset = mean(chunk$Y.N[1:10])
	chunk$Y.N.off = chunk$Y.N - yoffset
	zoffset = mean(chunk$Z.N[1:10]) 
	chunk$Z.N.off = chunk$Z.N - zoffset 
	# Calculate euclidean norm force
	for (r in 1:nrow(chunk)){
		xyz = as.matrix(chunk[r,c('X.N.off','Y.N.off','Z.N.off')])
		chunk$Norm[r] = norm(xyz,'2')
	}
	
	# Generate a plot of the data
	plot(x = chunk$Time.msec, y = chunk$Norm, 
			type = 'b',
			xlab = 'Elapsed time, ms', ylab = 'Net force, N', las = 1)
	par(xpd=FALSE)
	# Plot grey rectangle over the regions < 2 N on the y axis
	rect(par()$usr[1],par()$usr[3],par()$usr[2],2, col = rgb(.9,.9,.9,.8))
	grid(lty = 2, col = 'grey70')
	abline(h = 2, lty = 2, col = 'red', lwd = 2)
	# replot the force
	lines(x = chunk$Time.msec, y = chunk$Norm, type = 'b')
	# Draw 2 vertical lines on either side of the peak
	abline(v = chunk$Time.msec[peakIndex-1], lty = 2, col = 'black')
	abline(v = chunk$Time.msec[peakIndex+1], lty = 2, col = 'black')
	# Plot the baseline points
	points(x = chunk$Time.msec[1:baseLength], y = chunk$Norm[1:baseLength], 
			pch = 20,
			col = 'orange')
#	text(x = chunk$Time.msec[1], y = chunk$Norm[1], 
#			labels = 'Baseline', adj=c(0,-2))
	# Plot a point at the identified peak
	points(x = peaktime, y = chunk$Norm[peakIndex], pch = 20, cex = 2, 
			col='red')
	# Calculate the threshold value that is 1/2 of the peak value. For a Peck
	# the neighboring points for the peak would both need to be less than this
	# value (except in case where the peak is made of 2 points, in which case
	# the one large neighboring point isn't counted (yellow point in code below)
	halfThresh = 0.5 * chunk$Norm[peakIndex]
	# Plot points at the neighboring 2 samples (before and after)
	points(x = chunk$Time.msec[peakIndex-1], y = chunk$Norm[peakIndex-1],
			pch = 21, bg = ifelse(chunk$Norm[peakIndex-1] > halfThresh,
					'yellow','forestgreen'), cex = 1.5)
	points(x = chunk$Time.msec[peakIndex+1], y = chunk$Norm[peakIndex+1],
			pch = 21, bg = ifelse(chunk$Norm[peakIndex+1] > halfThresh,
					'yellow','forestgreen'), cex = 1.5)
	# Draw a line at half the height of the peak
	abline(h = halfThresh, col = 'forestgreen', lty = 3, lwd = 3) 
#	text(x = par()$usr[1], y = halfThresh, 
#			labels = '2x peck threshold, neighboring points must be below this line',
#			adj = c(-0.01,-0.5), col = 'forestgreen')
	text(x = par()$usr[1], y = halfThresh, 
			labels = '2x peck threshold',
			adj = c(-0.01,-0.5), col = 'forestgreen')
	text(x = par()$usr[1], y = 2, 
			labels = '2 Newton threshold', col = 'red',
			adj = c(-0.2,-0.5))
	text(x = chunk$Time.msec[peakIndex], y = chunk$Norm[peakIndex],
			labels = 'Peak', adj = -0.3)
	# Determine if this was a peck or push
	peckPush = peckPushAlgo(chunk$Norm, peakIndex = peakIndex,
			forceThreshold = forceThreshold)
    # Put an informative title on the plot
	mtext(side = 3, text = paste0(trialDate, ', ', 
					round(peaktime/1000,digits=2),'s, ', peckPush), 
			cex= 1.3, line = 1)
		
} 

#plotpeckpush(eventNum = 9, events = events2, forces = forces, calibs = calibCoeffs)

```

The code defines a function `peakPushAlgo()` to classify each peak event as either
a push or peck, when an sample force greater than 2 Newtons was identified. The
function `peckpushClassify()` then cycles through all identified events and
classifies them.  The code in `peakpushClassify()` also determines the duration of
each event, based on the time the force spent above the 2 Newton threshold
during that event. Because the raw data were sampled at 10 millisecond
intervals, a single peak force above 2 Newtons (peck) will have a 
maximum duration of 20
ms. That is the time it takes to go from ~0 N to >2 N and back to ~0 N over
the course of 3 samples.
However, based on our earlier definition of a Peck (1 OR 2 sample forces above
2N), we also include events where the force
was above the 2 N threshold for 2 samples in a row, which means the force was
above 2 N for at most 30 ms, which is the interval between 4 sample points.
Thus peck events will have a duration recorded in the output file of either 20
ms (single sample above 2 N, which takes a minimum of two 10 ms intervals to be
recorded by the transducer) or 30 ms (2 samples above 2 N, which takes a minimum
of three 10 ms intervals to be recorded by the transducer).   

For push
events, the duration of time the force is >2 N should end up longer than 
20 ms, where 20 ms encompasses 3 sampling time points, and durations longer than
20 ms encompass 4 or more sampling time points.
 The output of `peakpushClassify()` is a data frame similar to the input
events data frame, but with four new columns added on, `PeckPush`,
`Duration.msec`, `StartPeak.msec`, and `EndPeak.msec`. The latter two columns
list the time stamp in milliseconds where the algorithm declared the start and
end of a given event (the force exceeding the 2 Newton threshold). If an event
in the events data frame does not meet the critera for a peck or a push, these
new columns will contain NA. 

The results were saved to a csv file `Events_classified_20180213.csv`.


```{r classifyPeckPush, echo=showcode, cache=TRUE}
# Re-load the events file from the output of the peakChooser function above
baseLength = 8 # 8 sample baseline
peakThreshold = 2  # newtons   
events2 = read.csv(paste0(fdir,'Events_picker_output_20180213.csv'))
events2$Date = as.Date(events2$Date)   
events = events2
events3 = peckpushClassify(events = events2, forces = forces, 
		calibs = calibCoeffs, forceThreshold = 2, baseLength = baseLength)
events3$PeckPush = factor(events3$PeckPush)

# There are 2 duplicate events in the events3 data frame that should be removed
# before proceeding (one push, one peck)
# which(diff(events3$Time.msec) == 0)
events3 = events3[-c(28,53),]

# Remove all events that were classified NA for PeckPush
events3 = events3[!is.na(events3$PeckPush),] 

# Save the data frame with peck/push classifications as a new csv file. 
write.csv(events3, file = './Data/Events_classified_20200102.csv',row.names=FALSE)

```

```{r histPecks, echo=showcode,dpi = 300, fig.width = 6, fig.height = 8}
par(mfrow=c(2,1))  
hist(events3$Norm[events3$PeckPush == 'Peck'], 
		main = 'Peak forces for all Peck events', col = 'red', 
		ylim = c(0,140), las = 1, xlab = 'Force, Newtons')
hist(events3$Norm[events3$PeckPush == 'Push'], 
		main = 'Peak forces for all Push events', col = 'blue',
		ylim = c(0,140), las = 1, xlab = 'Force, Newtons')

```


```{r summaryTable, echo=showcode}

#events3 = read.csv(paste0(fdir,'Events_classified_20200102.csv'))



# Generate some summary statistics from the events3 data frame for Peck and 
# Push events
maxPeck = max(events3$Norm[events3$PeckPush == 'Peck'], na.rm=TRUE) 
minPeck = min(events3$Norm[events3$PeckPush == 'Peck'], na.rm=TRUE)
maxPush = max(events3$Norm[events3$PeckPush == 'Push'], na.rm=TRUE)
minPush = min(events3$Norm[events3$PeckPush == 'Push'], na.rm=TRUE)
meanPeck = mean(events3$Norm[events3$PeckPush == 'Peck'], na.rm=TRUE)
meanPush = mean(events3$Norm[events3$PeckPush == 'Push'], na.rm=TRUE)
sdPeck = sd(events3$Norm[events3$PeckPush == 'Peck'], na.rm=TRUE)
sdPush = sd(events3$Norm[events3$PeckPush == 'Push'], na.rm=TRUE)
medianPeck = median(events3$Norm[events3$PeckPush == 'Peck'], na.rm=TRUE)
medianPush = median(events3$Norm[events3$PeckPush == 'Push'], na.rm=TRUE)
nPeck = sum(!is.na(events3$Norm[events3$PeckPush == 'Peck']))
nPush = sum(!is.na(events3$Norm[events3$PeckPush == 'Push']))
# Subset top 10 percent
peck10 = events3[events3$PeckPush == 'Peck',]
peck10 = peck10[!is.na(peck10$PeckPush),] # Remove NA rows
peck10 = peck10[peck10$Norm >= quantile(peck10$Norm,prob=0.9),]
push10 = events3[events3$PeckPush == 'Push',]
push10 = push10[!is.na(push10$PeckPush),] # Remove NA rows
push10 = push10[push10$Norm >= quantile(push10$Norm,prob=0.9),]
meanPeckTop10 =  mean(peck10$Norm)
meanPushTop10 = mean(push10$Norm)
sdPeckTop10 = sd(peck10$Norm) 
sdPushTop10 = sd(push10$Norm)
nPeckTop10 = nrow(peck10)
nPushTop10 = nrow(push10)

summaryTable1 = data.frame(Max = c(maxPeck,maxPush), Min = c(minPeck,minPush),
		Mean = round(c(meanPeck,meanPush),dig=2), 
		SD = round(c(sdPeck,sdPush),dig=2), 
		Median = round(c(medianPeck,medianPush),dig=2),
		N = c(nPeck,nPush))
rownames(summaryTable1) = c('Peck','Push')
cat('Summary data for all identified events. Values are force in Newtons.\n')
summaryTable1


summaryTable2 = data.frame(
#		Max = c(maxPeck,maxPush), 
#		Min = c(minPeck,minPush),
		Mean = round(c(meanPeckTop10,meanPushTop10),dig=2), 
		SD = round(c(sdPeckTop10,sdPushTop10),dig=2), 
#		Median = round(c(medianPeck,medianPush),dig=2),
		N = c(nPeckTop10,nPushTop10))
rownames(summaryTable2) = c('Peck','Push')
cat('-----------------------------------\n')
cat('Summary data for the highest 10% of events. Values are force in Newtons.\n')
summaryTable2

# Separate horizontal/vertical data


```

Below are some example classified Pecks and Pushes. The figures have guidelines
showing where the thresholds are for classification as a peck or push. These
are not all of the events picked out. 


```{r NetForceSummary,echo=showcode}

cat('\nFraction of pecks greater than 14 Newtons net force (3 dimensions)\n') 
round(sum(abs(events3$Norm[events3$PeckPush == 'Peck']) > 14) / 
		length(events3$Norm[events3$PeckPush == 'Peck']),dig=4)

cat('\nFraction of pushes greater than 14 Newtons net force (3 dimensions)\n')
round(sum(abs(events3$Norm[events3$PeckPush == 'Push']) > 14) / 
		length(events3$Norm[events3$PeckPush == 'Push']),dig=4)

```



```{r plotPeckPushes,echo=showcode,cache=TRUE, fig.height = 10, fig.width=8,dpi=300,dev='png'}
# Make some example plots
for (i in seq(1,36,by = 6)){ 
	par(mfrow = c(3,2) ) 
	for (j in i:(i+5)){
		plotpeckpush(eventNum = j, events = events2, forces = forces, 
				calibs = calibCoeffs, forceThreshold = 2, baseLength=baseLength)	
	}
	
}
par(mfrow=c(1,1))  

```

```{r examplePeckPushPlots,echo=showcode,dpi=600,dev=c('png','pdf'),fig.width=6,fig.height=6,fig.cap='Examples of net forces exerted by the captive bird on the force transducer. Data from 2016-12-14 at 621.5 sec elapsed'}
# Plot example data from 2016-12-14 trial at 621000 msec elapsed time
op = par(mfrow=c(2,1), mar = c(5,5.5,0.5,1))
par(family='serif')
textadj = -0.22
textcex = 1.5 
textLine = -0.8
ptcex = 0.5
i = 16
trialDate = events$Date[i]
tempcalibs = calibCoeffs[[which.min(abs(calibDates-(trialDate-1)))]]

chunk = forces[forces$Time.msec > 621000 & forces$Time.msec < 624100, ]
chunk = chunk[chunk$Date == trialDate,]
chunk$X.N = (chunk$JOY_X_signal * tempcalibs$X$slope) + 
		tempcalibs$X$intercept
chunk$Y.N = (chunk$JOY_Y_signal * tempcalibs$Y$slope) + 
		tempcalibs$Y$intercept
chunk$Z.N = (chunk$BEAM_Z_signal * tempcalibs$Z$slope) + 
		tempcalibs$Z$intercept

# Apply offset based on the average of the baseline values (10 samples)
xoffset = mean(chunk$X.N[1:10])
chunk$X.N.off = chunk$X.N - xoffset
yoffset = mean(chunk$Y.N[1:10])
chunk$Y.N.off = chunk$Y.N - yoffset
zoffset = mean(chunk$Z.N[1:10]) 
chunk$Z.N.off = chunk$Z.N - zoffset 
# Calculate euclidean norm force
for (r in 1:nrow(chunk)){
	xyz = as.matrix(chunk[r,c('X.N.off','Y.N.off','Z.N.off')])
	chunk$Norm[r] = norm(xyz,'2')
}

# Generate a plot of the data
plot(x = chunk$Time.msec, y = chunk$Norm, 
		type = 'n',
		xlab = 'Elapsed time (s)', ylab = 'Net force (N)', las = 1,
		xaxt = 'n',
		ylim = c(0,35),
		pch = 20)
prettyvals = pretty(chunk$Time.msec)
prettyvalsTenthSec = seq(prettyvals[1],prettyvals[length(prettyvals)],by = 100)
abline(v = prettyvalsTenthSec,
		lty = 3, col = 'grey50')
abline(h = 0, lty = 3, col = 'grey50')
lines(x = chunk$Time.msec, y = chunk$Norm)
points(x = chunk$Time.msec, y = chunk$Norm, pch = 20, cex = ptcex)

# Draw 0.1 sec tick marks
axis(side = 1, at = prettyvalsTenthSec, 
		labels = rep('',length(prettyvalsTenthSec)), tcl = -0.2)
# Label the 1/2 sec tick marks
axis(side = 1, at = pretty(chunk$Time.msec),
		labels = pretty(chunk$Time.msec - chunk$Time.msec[1])/1000)

mtext(side = 3, text = 'A', line = textLine, adj = textadj, cex = textcex)
###################
# Close-up plot of peck and push from same data chunk
chunk2 = forces[forces$Time.msec > 621480 & forces$Time.msec < 621720, ]
chunk2 = chunk2[chunk2$Date == trialDate,]
chunk2$X.N = (chunk2$JOY_X_signal * tempcalibs$X$slope) + 
		tempcalibs$X$intercept
chunk2$Y.N = (chunk2$JOY_Y_signal * tempcalibs$Y$slope) + 
		tempcalibs$Y$intercept
chunk2$Z.N = (chunk2$BEAM_Z_signal * tempcalibs$Z$slope) + 
		tempcalibs$Z$intercept

# Apply offset based on the average of the baseline values (10 samples)
xoffset = mean(chunk2$X.N[1:7])
chunk2$X.N.off = chunk2$X.N - xoffset
yoffset = mean(chunk2$Y.N[1:7])
chunk2$Y.N.off = chunk2$Y.N - yoffset
zoffset = mean(chunk2$Z.N[1:7]) 
chunk2$Z.N.off = chunk2$Z.N - zoffset 
# Calculate euclidean norm force
for (r in 1:nrow(chunk2)){
	xyz = as.matrix(chunk2[r,c('X.N.off','Y.N.off','Z.N.off')])
	chunk2$Norm[r] = norm(xyz,'2')
}

# Generate a plot of the data
plot(x = chunk2$Time.msec, y = chunk2$Norm, 
		type = 'n',
		xlab = 'Elapsed time (s)', ylab = 'Net force (N)', las = 1,
		xaxt = 'n',
		ylim = c(0,15))
abline(h = 0, lty = 3, col = 'grey50')
lines(x = chunk2$Time.msec, y = chunk2$Norm)
points(x = chunk2$Time.msec, y = chunk2$Norm, pch = 20)
#prettyvals = pretty(chunk$Time.msec)
#prettyvalsTenthSec = seq(prettyvals[1],prettyvals[length(prettyvals)],by = 100)
axis(side = 1, at = prettyvalsTenthSec, labels = rep('',length(prettyvalsTenthSec)))
axis(side = 1, at = prettyvalsTenthSec,
		labels = (prettyvalsTenthSec-prettyvalsTenthSec[1])/1000)
#abline(v = prettyvalsTenthSec,
#		lty = 3, col = 'grey50')

mtext(side = 3, text = 'B', line = textLine, adj = textadj, cex = textcex)

```


```{r eventInterval,echo=showcode}
# Estimate time between strikes using the peck/push data in events3

# Get the available experiment dates
mydates = unique(events3$Date)

for (i in 1:length(mydates)) {
	# subset data for a given date
	temp = events3[events3$Date == mydates[i],]
	# Make sure they are ordered by time
	temp = temp[order(temp$Time.msec),]
	# Calculate the difference in milliseconds between each event ('Time.msec'
	# column)
	interval = diff(temp$Time.msec)
	# Ignore intervals greater than an arbitrary length (10 seconds)
	interval = interval[interval < 10000]
	# Extract summary stats
	sums = summary(interval)
	if (i == 1){
		intervalData = data.frame(Date = temp$Date[1], 
				Median.msec = as.numeric(sums[3]),
				Mean.msec = as.numeric(sums[4]),
				SampleSize = length(interval))
	} else {
		intervalData = rbind(intervalData, 
				data.frame(Date = temp$Date[1], 
						Median.msec = as.numeric(sums[3]),
						Mean.msec = as.numeric(sums[4]),
						SampleSize = length(interval)))
	}
}	

```


```{r boutCount, echo=showcode}
# Get the available experiment dates
mydates = unique(events3$Date)
BoutCounter = 1
if (exists('BoutIntervalData')) rm(BoutIntervalData)
for (i in 1:length(mydates)) {
	# subset data for a given date
	temp = events3[events3$Date == mydates[i],]
	# Make sure they are ordered by time
	temp = temp[order(temp$Time.msec),]
	# Calculate the difference in milliseconds between each event ('Time.msec'
	# column)
	interval = diff(temp$Time.msec)
	# Find intervals greater than an arbitrary length (10 seconds, 10000 msec)
	GapInterval = which(interval > 10000)
	# If the first entry is a large gap, remove it
	if (GapInterval[1] == 1) GapInterval = GapInterval[-1]
	
	
	GapInterval = c(0,GapInterval,length(interval)+1)  # add index for event 1
	# and the last event
	
	if (length(GapInterval)>0){
		# Go through the intervals that are separated by less than 10000
		for (j in 1:(length(GapInterval)-1)){
			temp2 = interval[(GapInterval[j]+1):(GapInterval[j+1]-1)]
			# Extract summary stats
			sums =  summary(temp2)
			# Filter for cases where the median is longer than 10 seconds, 
			# as these will represent cases where the bird struck once and then
			# waited 10+ seconds to strike again, which means we can't estimate
			# the within-bout strike interval
			if (sums[3] < 10000) {
					if (!exists('BoutIntervalData')){
						BoutIntervalData = data.frame(Date = temp$Date[1], 
								Median.msec = as.numeric(sums[3]),
								Mean.msec = as.numeric(sums[4]),
								SampleSize = length(temp2),
								Attack = BoutCounter)
						BoutCounter = BoutCounter + 1
					} else {
						BoutIntervalData = rbind(BoutIntervalData, 
								data.frame(Date = temp$Date[1], 
										Median.msec = as.numeric(sums[3]),
										Mean.msec = as.numeric(sums[4]),
										SampleSize = length(temp2),
										Attack = BoutCounter))
						BoutCounter = BoutCounter + 1
					}
				}
		}	
	} else {  # If there were no 10+sec gaps on this date
		# Extract summary stats
		sums = summary(interval)
		BoutIntervalData = rbind(BoutIntervalData, 
				data.frame(Date = temp$Date[1], 
						Median.msec = as.numeric(sums[3]),
						Mean.msec = as.numeric(sums[4]),
						SampleSize = length(interval),
						Attack = BoutCounter))
		BoutCounter = BoutCounter + 1
	}
	
}


```


```{r intervalTable,echo=showcode,results='asis'}
kable(intervalData, caption = "Median and mean interval (milliseconds) between 
strikes (less than 10 seconds apart), on each sampling date.") 

```

```{r BoutintervalTable,echo=showcode,results='asis'}
kable(BoutIntervalData, caption = "Median and mean interval (milliseconds) between 
strikes, for all events spaced less than 10 seconds apart. Each event is defined
as a series of strikes that occured no more than 10 seconds apart. The number
of strikes in each attack is given, along with the attack number identifier.") 

```



# Peck/Push direction

We can use the 3-dimensional force data to estimate the direction/angle that
the bird attacked the mimic limpet at. 

```{r calcDirection,echo=showcode}
# First calculate net force in X-Y axis, holding on to the positive/negative
# component of the Y-axis. A positive Y value is a force applied from the
# rear of the shell towards the anterior, and a negative Y value would indicate
# a force applied at the anterior end of the shell pushing towards the posterior.
# We'll ignore directionality in the X axis (left-right) since the animal
# is mostly symmetrical on either side of the anterior-posterior axis. 
# So each pair of X-Y forces will be converted into a net horizontal force with
# a fore-aft direction, and then we'll add on the vertical force to estimate
# overall net direction in the Y-Z plane. 

# Data are in the data frame events3. The columns X.N.off, Y.N.off, and Z.N.off
# contain the offset-corrected forces in Newtons for the X, Y, Z axes. First 
# subset events3 to remove events that were classified as NA instead of Peck 
# or Push
events4 = events3 

forceDir = events4[,c('EventNumber','Date','Time.msec','PeckPush','Norm',
				'X.N.off','Y.N.off','Z.N.off')]
forceDir$horizForce.N = NA  # net X-Y axis force
forceDir$horizAngle = NA # direction of force in the horizontal plane
forceDir$netForce.N = NA # net including z-axis force (3-D force)
forceDir$vertRadians = NA
forceDir$vertAngle = NA

for (i in 1:nrow(events4)){
	# Calculate the 2-norm of the X and Y axes, and multiple by the sign of the 
	# Y-axis data (keeps negative Y values as negatives, ignores X axis sign)
	forceDir$horizForce.N[i] = norm(as.matrix(c(events4$X.N.off[i],
									events4$Y.N.off[i])), '2') * 
			sign(events4$Y.N.off[i]) 
	forceDir$horizAngle[i] = atan2(events4$Y.N.off[i], events4$X.N.off[i])* 180/pi
	
	# Negative horizontal force values indicate posterior-directed force 
	# To calculate vertical direction, use the sign from Z.N.off and ignore
	# the sign from horizForce.N
	forceDir$netForce.N[i] = norm(as.matrix(c(forceDir$horizForce.N[i],
									events4$Z.N.off[i])),'2') * 
			sign(events4$Z.N.off[i])
	# Calculate angle (in radians) between horizontal plane and the vector 
	# of Z and horizForce.N
	forceDir$vertRadians[i] = atan2(events4$Z.N.off[i], forceDir$horizForce.N[i])
	# Convert to degrees
	forceDir$vertAngle[i] = (forceDir$vertRadians[i] * 180/pi) 
	# Note that the value calculated in vertForce.N should be the same as
	# the value in the Norm column carried over from events4 (ignoring sign)
	
}
```

```{r horizForceSummary,echo=showcode}
# Maximum forces in the horizontal plane (shearing force)
cat('Strongest overall force in horizontal plane (this was a peck), Newtons\n')
(maxHorizForce = max(abs(forceDir$horizForce.N)))

cat('\nStrongest push force in horizontal plane, Newtons\n') 
max(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Push']))

cat('\nFraction of horizontal pecks greater than 14 Newtons\n') 
sum(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Peck']) > 14) / 
		length(forceDir$horizForce.N[forceDir$PeckPush == 'Peck'])

cat('\nFraction of horizontal pushes greater than 14 Newtons\n')
sum(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Push']) > 14) / 
		length(forceDir$horizForce.N[forceDir$PeckPush == 'Push'])

```


```{r forceHistograms,echo=showcode,dev=c('png','pdf'), dpi=300,fig.width=6,fig.height=6,fig.cap='Histogram of forces in the horizontal plane (A,B) and three dimensions (C,D), classified as pecks or pushes. Left column shows events classified as pecks (n = 217), right column shows events classified as pushes (n = 136). Points and error bars represent the mean +/- 1 SD.'}
# 4-panel plot of force histograms, divided up by peck vs push, and horizontal
# vs 3-D forces. Also added points and error bars representing mean + 1SE
op = par(mfrow=c(2,2))
pointY = 95
mybreaks = seq(0,40,by=2) 
textLine = 1.8
textadj = -0.3
textcex = 1.5 
ylims = c(0,100)
par(family='serif')
histInfo = hist(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Peck']), 
		main = 'Peck force, horizontal plane',
		xlab = 'Net force in horizontal plane (N)', ylab = 'Frequency',
		col = 'grey40', las = 1, ylim = ylims, xlim = c(0,40),
		breaks = mybreaks)
mtext(side = 3, text = 'A', line = textLine, adj = textadj, cex = textcex)
# Add point for mean and SE
peckHorizMean = mean(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Peck']))
peckHorizSD = sd(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Peck']))
peckHorizSample = length(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Peck']))
#peckHorizLength = length(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Peck']))
#peckHorizSE = peckHorizSD / sqrt(peckHorizLength)
points(x = peckHorizMean, y = pointY, pch = 20, cex = 1.5)
arrows(x0 = peckHorizMean - peckHorizSD, x = peckHorizMean + peckHorizSD,
		y0 = pointY, y1 = pointY, length = 0.05,
		angle = 90, code = 3)



hist(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Push']), 
		main = 'Push force, horizontal plane',
		xlab = 'Net force in horizontal plane (N)', ylab = 'Frequency',
		col = 'grey40', las = 1, ylim = ylims, xlim = c(0,40),
		breaks = mybreaks)
mtext(side = 3, text = 'B', line = textLine, adj = textadj, cex = textcex)
# Add point for mean and SE
pushHorizMean = mean(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Push']))
pushHorizSD = sd(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Push']))
pushHorizSample = length(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Push']))
#pushHorizLength = length(abs(forceDir$horizForce.N[forceDir$PeckPush == 'Push']))
#pushHorizSE = pushHorizSD / sqrt(pushHorizLength)
points(x = pushHorizMean, y = pointY, pch = 20, cex = 1.5)
arrows(x0 = pushHorizMean - pushHorizSD, x = pushHorizMean + pushHorizSD,
		y0 = pointY, y1 = pointY, length = 0.05,
		angle = 90, code = 3)



hist(abs(forceDir$netForce.N[forceDir$PeckPush == 'Peck']), 
		main = 'Peck force, 3 dimensions',
		xlab = 'Net force in 3 dimensions (N)', ylab = 'Frequency',
		col = 'grey40', las = 1, ylim = ylims, xlim = c(0,40),
		breaks = mybreaks)
mtext(side = 3, text = 'C', line = textLine, adj = textadj, cex = textcex)
# Add point for mean and SE
peck3DMean = mean(abs(forceDir$netForce.N[forceDir$PeckPush == 'Peck']))
peck3DSD = sd(abs(forceDir$netForce.N[forceDir$PeckPush == 'Peck']))
#peck3DLength = length(abs(forceDir$netForce.N[forceDir$PeckPush == 'Peck']))
#peck3DSE = peck3DSD / sqrt(peck3DLength)
points(x = peck3DMean, y = pointY, pch = 20, cex = 1.5)
arrows(x0 = peck3DMean - peck3DSD, x = peck3DMean + peck3DSD,
		y0 = pointY, y1 = pointY, length = 0.05,
		angle = 90, code = 3)


hist(abs(forceDir$netForce.N[forceDir$PeckPush == 'Push']), 
		main = 'Push force, 3 dimensions',
		xlab = 'Net force in 3 dimensions (N)', ylab = 'Frequency',
		col = 'grey40', las = 1, ylim = ylims, xlim = c(0,40),
		breaks = mybreaks)
mtext(side = 3, text = 'D', line = textLine, adj = textadj, cex = textcex)
# Add point for mean and SE
push3DMean = mean(abs(forceDir$netForce.N[forceDir$PeckPush == 'Push']))
push3DSD = sd(abs(forceDir$netForce.N[forceDir$PeckPush == 'Push']))
#push3DLength = length(abs(forceDir$netForce.N[forceDir$PeckPush == 'Push']))
#push3DSE = push3DSD / sqrt(push3DLength)
points(x = push3DMean, y = pointY, pch = 20, cex = 1.5)
arrows(x0 = push3DMean - push3DSD, x = push3DMean + push3DSD,
		y0 = pointY, y1 = pointY, length = 0.05,
		angle = 90, code = 3)
par(op)
```

* For horizontal pecks, the mean + 1SD was 
`r round(peckHorizMean,dig=3)` + `r round(peckHorizSD,dig=3)`. Sample size was `r peckHorizSample`.
* For horizontal pushes, the mean + 1SD was 
`r round(pushHorizMean,dig=3)` + `r round(pushHorizSD,dig=3)`. Sample size was `r pushHorizSample`.
* For pecks in 3 dimensions, the mean + 1SD was
`r round(peck3DMean,dig=3)` + `r round(peck3DSD,dig=3)`. Sample size was `r peckHorizSample`.
* For pushes in 3 dimensions, the mean + 1SD was 
`r round(push3DMean,dig=3)` + `r round(push3DSD,dig=3)`. Sample size was `r pushHorizSample`.


```{r avgStrikeAngles, strikeAngles,echo=showcode}
# Generate some data frames of force direction in the fore-aft/up-down axes,
# but pooling the fore-aft data so that we can just look at average strike
# angles relative to the horizontal plane (i.e. downward-directed strikes or
# upward-directed). 

library(circular, quietly = TRUE)
# All forceDir$vertAngle values with negative values are downwards-directed strikes.
# Values from 0 to -90 are downwards towards the anterior, while -90 to -180
# are downwards towards the posterior. Any positive values are upwards strikes.

# Subset the negative (downward) angle data
vertAngle = forceDir$vertAngle[forceDir$vertAngle < 0]
# Mirror the anterior values to be posterior-directed so we can just get
# a summary of the average downward angle, ignoring fore/aft direction. 
vertAngle[vertAngle>-90] = (180 + vertAngle[vertAngle>-90])*-1
vertAngle = circular(vertAngle, units='degrees', template = 'none')


# Take all angle data and mirror so that it's all posterior-directed
allAngles = forceDir$vertAngle
# First flip all of the anterior-ventral-directed forces to posterior-ventral
allAngles[allAngles>-90 & allAngles<0] = (180+allAngles[allAngles>-90 & allAngles<0])*-1
# Next flip all anterior-dorsal-directed forces to posterior-dorsal
allAngles[allAngles>=0 & allAngles<90] = (180+allAngles[allAngles>=0 & allAngles<90])
# Convert to circular object. 
af = circular(allAngles, units='degrees', template = 'none')
# Now all of the values just represent an angle above (positive) or below 
# (negative) horizontal, with a value of +/- 180 being horizontal-posterior


############################
## Plot for testing purposes
#shrinkval = 1
#par(xpd=TRUE)
#sepVal = 0.04
#panelLetterAdj = 0.01 
#letterLine = 1.5
## convert original angles to a circular object
#f <- circular(forceDir$vertAngle, units='degrees',
#		template = 'none')
#plot2 = plot(f, type = 'n', shrink = shrinkval, rotation = 'counter', zero = 0, 
#		axes = FALSE)
## Angle labels
#axis.circular(template = 'none', units='degrees', zero = 0, lty = 1, 
#		tcl.text = 0.20, at = NULL, labels = rep('',4), tcl = 0.1,
#		lwd = 1.5)
## Body axis labels
#axis.circular(template = 'none',units='degrees',zero = 0,rotation='counter', 
#		labels=c('Ventral','Dorsal'), 
#		tcl.text = -0.2,
#		at = c(circular(c(270,90),units='degrees',template='none')))
#axis.circular(template = 'none',units='degrees',zero = 0,rotation='counter', 
#		labels=c('Anterior','Posterior'), 
#		tcl.text = -0.45,
#		at = c(circular(c(-7,185),units='degrees',template='none')))
## Plot the original set of angles
#points.circular(f, stack = TRUE, bins = 360, shrink =1.3, 
#		rotation = 'counter', zero = 0,
#		pch = 20, plot.info = plot2, sep = sepVal)
## Plot the version with all directions flipped to posterior-directed
#points.circular(af, stack = TRUE, bins = 360, shrink =1.3, 
#		rotation = 'counter', zero = 0,
#		pch = 1, plot.info = plot2, sep = sepVal, col = 'red')	

# Unload circular package to avoid interference with mean() and sd() functions
detach('package:circular', unload=TRUE)
```

```{r summaryStrikeAngles,echo=TRUE}
library(circular, quietly = TRUE)

# Summary stats for only the downward-directed strikes (n=226)
# We are subtracting 180 here just to make the numbers come out as positive
# values representing angle *below* horizontal
summary(vertAngle-180)
mle.vonmises.bootstrap.ci(vertAngle-180)
#
#
# Summary stats for all strikes, downwards, horizontal, upwards (n=353)
# Here again we subtract off 180 so that a *downward* directed force shows
# up as a positive value representing angle *below* horizontal
summary(af-180) 
mle.vonmises.bootstrap.ci(af-180)
# Unload circular package to avoid interference with mean() and sd() functions
detach('package:circular', unload=TRUE)
```

For the subset of strikes that were directed downwards towards the limpet
(`r summary(vertAngle)[1]`),
the mean strike angle was from `r round(summary(vertAngle-180)[5],dig=3)` degrees
above horizontal. 

For all of the strikes (downwards, horizontal, or upwards, `r summary(af)[1]`),
the mean strike angle was from `r round(summary(af-180)[5],dig=3)` degrees above
horizontal. 



```{r addImgFunction,echo=showcode}
# Make a function to help ease adding PNG image into the plots below
# From: https://stackoverflow.com/questions/27800307/adding-a-picture-to-plot-in-r

addImg <- function(
		obj, # an image file imported as an array (e.g. png::readPNG, jpeg::readJPEG)
		x = NULL, # mid x coordinate for image
		y = NULL, # mid y coordinate for image
		width = NULL, # width of image (in x coordinate units)
		interpolate = TRUE # (passed to graphics::rasterImage) A logical vector (or scalar) indicating whether to apply linear interpolation to the image when drawing. 
){
	if(is.null(x) | is.null(y) | is.null(width)){stop("Must provide args 'x', 'y', and 'width'")}
	USR <- par()$usr # A vector of the form c(x1, x2, y1, y2) giving the extremes of the user coordinates of the plotting region
	PIN <- par()$pin # The current plot dimensions, (width, height), in inches
	DIM <- dim(obj) # number of x-y pixels for the image
	ARp <- DIM[1]/DIM[2] # pixel aspect ratio (y/x)
	WIDi <- width/(USR[2]-USR[1])*PIN[1] # convert width units to inches
	HEIi <- WIDi * ARp # height in inches
	HEIu <- HEIi/PIN[2]*(USR[4]-USR[3]) # height in units
	rasterImage(image = obj, 
			xleft = x-(width/2), xright = x+(width/2),
			ybottom = y-(HEIu/2), ytop = y+(HEIu/2), 
			interpolate = interpolate)
}

library(png)
imgTop = readPNG('Lgigantea_top_view_cutout.png')
imgSide = readPNG("Lgigantea_profile_cutout.png")

```

```{r circularPlotFunctions, echo=showcode}
# Here's some modified functions from the 'circular' package to allow me to 
# plot stacked points on a circle, but using a color for each point to represent
# the associated force. 
 
my.points.circular <- function (x, pch = 16, cex = 1, stack = FALSE, start.sep = 0, 
		sep = 0.025, shrink = 1, bins = NULL, col = NULL, next.points = NULL, 
		plot.info = NULL, zero = NULL, rotation = NULL, mycols, ...) 
{
	if (is.matrix(x) | is.data.frame(x)) {
		nseries <- ncol(x)
	}
	else {
		nseries <- 1
	}
	xx <- as.data.frame(x)
	xcircularp <- attr(as.circular(xx[, 1]), "circularp")
	type <- xcircularp$type
	modulo <- xcircularp$modulo
	if (is.null(plot.info)) {
		if (is.null(zero)) 
			zero <- xcircularp$zero
		if (is.null(rotation)) 
			rotation <- xcircularp$rotation
		if (is.null(next.points)) 
			next.points <- 0
	}
	else {
		zero <- plot.info$zero
		rotation <- plot.info$rotation
		if (is.null(next.points)) 
			next.points <- plot.info$next.points
	}
	if (is.null(bins)) {
		bins <- NROW(x)
	}
	else {
		bins <- round(bins)
		if (bins <= 0) 
			stop("bins must be non negative")
	}
	if (is.null(col)) {
		col <- seq(nseries)
	}
	else {
		if (length(col) != nseries) {
			col <- rep(col, nseries)[1:nseries]
		}
	}
	pch <- rep(pch, nseries, length.out = nseries)
	for (iseries in 1:nseries) {
		x <- xx[, iseries]
		x <- na.omit(x)
		n <- length(x)
		if (n) {
			x <- conversion.circular(x, units = "radians")
			attr(x, "circularp") <- attr(x, "class") <- NULL
			if (rotation == "clock") 
				x <- -x
			x <- x + zero
			x <- x%%(2 * pi)
			my.PointsCircularRad(x, bins, stack, col, pch, iseries, 
					nseries, start.sep, sep, next.points, shrink, 
					cex, mycols, ...)
		}
	}
	return(invisible(list(zero = zero, rotation = rotation, next.points = next.points + 
									nseries * sep)))
}
## Subfunction my.PointsCircularRad
# mycols should be a vector of colors sorted in the same order as the 
# angular data that are in the vector x
my.PointsCircularRad <- function (x, bins, stack, col, pch, iseries, nseries, start.sep, 
		sep, next.points, shrink, cex, mycols,...) 
{
	if (!stack) {
		z <- cos(x)
		y <- sin(x)
		r <- 1 + ((iseries - 1) * sep + next.points + start.sep) * 
				shrink
		points.default(z * r, y * r, cex = cex, pch = pch[iseries], 
				col = col[iseries], ...)
	}
	else {
		x[x >= 2 * pi] <- 2 * pi - 4 * .Machine$double.eps
		arc <- (2 * pi)/bins
		pos.bins <- ((1:nseries) - 1/2) * arc/nseries - arc/2
		breaks <- seq(0, 2 * pi, length.out = (bins + 1))
		# Here you call histogram function to generate counts of how many
		# values fall within each of the bins (breaks). At this point you
		# lose the direct connection between the original data points and
		# what gets plotted, since the plotting function just plots based
		# on the bin's angle and number of points in the bin. 
		bins.count <- hist.default(x, breaks = breaks, plot = FALSE, 
				right = TRUE)$counts
		mids <- seq(arc/2, 2 * pi - pi/bins, length = bins) + 
				pos.bins[iseries]
		index <- cex * sep
		for (i in 1:bins) {
			if (bins.count[i] != 0) {
				# If there are values in this bin, do the following:
				# The current bin runs from breaks[i] to breaks[i+1], so 
				# we want to find rows in x that are within that interval,
				# and get their associated force values from the original 
				# data frame
				xindex = which(x >= breaks[i] & x < breaks[i+1])
				# Assume xindex holds row indices in the original data frame
				# Get color values from the mycols vector of colors, which 
				# should correspond to the forces for the chosen rows of x
				colvals = mycols[xindex]
				
				for (j in 0:(bins.count[i] - 1)) {
					r <- 1 + start.sep + j * index
					z <- r * cos(mids[i])
					y <- r * sin(mids[i])
					points.default(z, y, cex = cex, pch = pch[iseries], 
#							col = col[iseries], ...)
							col = colvals[j+1], ...) # Plot color from colvals
				}
			}
		}
	}
}

```


```{r circularAnglePlot,fig.show='hide',cache=TRUE,echo=showcode,dpi=600, fig.width=7,fig.height = 9,fig.cap='Angular distribution of force vectors for pecks and pushes along the A) anterior-posterior and left-right axes and B) anterior-posterior and dorsal-ventral axes of the limpet mimic. Each point represents the resultant direction of a single strike event by the black oystercatcher during trials on 6 dates.'}
library(circular, quietly = TRUE)

par(mfrow=c(2,1)) 
shrinkval = 0.8
sepVal = 0.04
panelLetterAdj = 0.01 
letterLine = 1.5
# Make a simple plot of the distribution of fore-aft & left-right directional
# data for the peaks and pushes together.
h <- circular(forceDir$horizAngle, units='degrees',
		template = 'none')
par(xpd=TRUE)
thisplot = plot(h, type = 'n', shrink = shrinkval, rotation = 'clock', zero = pi/2, 
		axes=FALSE, tol = 0.01)
# Angle labels
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		lty = 1, tcl.text = 0.15, at = NULL, labels = rep('',4), tcl = 0.1,
		lwd = 1.5)
par(xpd=TRUE)
# Body axis labels
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		labels=c('Anterior','Posterior'), tcl.text = -0.25,
		at = c(circular(c(90,270), units='degrees', template='none')))
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		labels=c('Right','Left'), tcl.text = -0.25, 
		at = c(circular(c(0,180), units='degrees', template='none')))
# Plot the stacked points
points.circular(h, stack = TRUE, bins = 360, shrink =1.3, 
		rotation = 'counter', zero = pi/2,
		pch = 20, sep = sepVal)	
par(xpd=FALSE)
mtext(side = 3, text = 'A', cex = 2.5, adj = panelLetterAdj, line = letterLine)
# Add limpet image to center
addImg(imgTop,x = 0,y = 0,width = 1.2,interpolate=TRUE)

####################################################################
####################################################################
# Make a plot of the distribution of vertical and fore-aft directional
# data for the peaks and pushes together.
par(xpd=TRUE)
f <- circular(forceDir$vertAngle, units='degrees',
				template = 'none')
plot2 = plot(f, type = 'n', shrink = shrinkval, rotation = 'counter', zero = 0, 
		axes = FALSE)
#abline(h = 0, lty = 2)
#abline(v = 0, lty = 2)
# Angle labels
axis.circular(template = 'none', units='degrees', zero = 0, lty = 1, 
		tcl.text = 0.20, at = NULL, labels = rep('',4), tcl = 0.1,
		lwd = 1.5)

#axis.circular(template = 'none', units='degrees', zero = 0, lty = 1, 
#		tcl.text = 0.20, at = NULL, tcl = 0.1,
#		lwd = 1.5)

# Body axis labels
axis.circular(template = 'none',units='degrees',zero = 0,rotation='counter', 
		labels=c('Ventral','Dorsal'), 
		tcl.text = -0.2,
		at = c(circular(c(270,90),units='degrees',template='none')))

axis.circular(template = 'none',units='degrees',zero = 0,rotation='counter', 
		labels=c('Anterior','Posterior'), 
		tcl.text = -0.45,
		at = c(circular(c(-7,185),units='degrees',template='none')))
 
points.circular(f, stack = TRUE, bins = 360, shrink =1.3, 
		rotation = 'counter', zero = 0,
		pch = 20, plot.info = plot2, sep = sepVal)	
mtext(side = 3, text = 'B', cex = 2.5, adj = panelLetterAdj, line = letterLine)
# Add Lottia image side view
addImg(imgSide,x = 0,y = 0.2,width = 1.7,interpolate=TRUE)

# Unload circular package to avoid interference with mean() and sd() functions
detach('package:circular', unload=TRUE)

```


```{r circularAnglePecksOnlyPlot,fig.show='hide',cache=TRUE,echo=showcode,dpi=600, fig.width=7,fig.height = 9,fig.cap='Angular distribution of force vectors for pecks along the A) anterior-posterior and left-right axes and B) anterior-posterior and dorsal-ventral axes of the limpet mimic. Each point represents the resultant direction of a single strike event classified as a peck by the black oystercatcher during trials on 6 dates.'}
library(circular, quietly = TRUE)

par(mfrow=c(2,1))
shrinkval = 0.8 
sepVal = 0.04
panelLetterAdj = 0.01
letterLine = 1.5
# Make a simple plot of the distribution of fore-aft & left-right directional
# data for the peaks and pushes together.
hpecks <- circular(forceDir$horizAngle[forceDir$PeckPush == 'Peck'], units='degrees',
		template = 'none')
par(xpd=TRUE)
thisplot = plot(hpecks, type = 'n', shrink = shrinkval, rotation = 'clock', zero = pi/2, 
		axes=FALSE, tol = 0.01)
# Angle labels
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		lty = 1, tcl.text = 0.15, at = NULL, labels = rep('',4), tcl = 0.1,
		lwd = 1.5)
par(xpd=TRUE)
# Body axis labels
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		labels=c('Anterior','Posterior'), tcl.text = -0.25,
		at = c(circular(c(90,270), units='degrees', template='none')))
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		labels=c('Right','Left'), tcl.text = -0.25, 
		at = c(circular(c(0,180), units='degrees', template='none')))
# Plot the stacked points
points.circular(hpecks, stack = TRUE, bins = 360, shrink =1.3, 
		rotation = 'counter', zero = pi/2,
		pch = 20, sep = sepVal)	
par(xpd=FALSE)
mtext(side = 3, text = 'A', cex = 2.5, adj = panelLetterAdj, line = letterLine)
# Add limpet image to center
addImg(imgTop,x = 0,y = 0,width = 1.2,interpolate=TRUE)

####################################################################
####################################################################
# Make a plot of the distribution of vertical and fore-aft directional
# data for the peaks and pushes together.
par(xpd=TRUE)
fpecks <- circular(forceDir$vertAngle[forceDir$PeckPush == 'Peck'], units='degrees',
				template = 'none')
plot2 = plot(fpecks, type = 'n', shrink = shrinkval, rotation = 'counter', zero = 0, 
		axes = FALSE)
# Angle labels
axis.circular(template = 'none', units='degrees', zero = 0, lty = 1, 
		tcl.text = 0.20, at = NULL, labels = rep('',4), tcl = 0.1,
		lwd = 1.5)
# Body axis labels
axis.circular(template = 'none',units='degrees',zero = 0,rotation='counter', 
		labels=c('Ventral','Dorsal'), 
		tcl.text = -0.2,
		at = c(circular(c(270,90),units='degrees',template='none')))

axis.circular(template = 'none',units='degrees',zero = 0,rotation='counter', 
		labels=c('Anterior','Posterior'), 
		tcl.text = -0.45,
		at = c(circular(c(-7,185),units='degrees',template='none')))

points.circular(fpecks, stack = TRUE, bins = 360, shrink =1.3, 
		rotation = 'counter', zero = 0,
		pch = 20, plot.info = plot2, sep = sepVal)	
mtext(side = 3, text = 'B', cex = 2.5, adj = panelLetterAdj, line = letterLine)
# Add Lottia image side view
addImg(imgSide,x = 0,y = 0.2,width = 1.7,interpolate=TRUE)

# Unload circular package to avoid interference with mean() and sd() functions
detach('package:circular', unload=TRUE)

```





```{r circularAngleColorPlot,echo=showcode,dev=c('png','pdf'),dpi=300, cache=TRUE,fig.width=7,fig.height = 9,fig.cap='Angular distribution of force vectors for pecks and pushes along the A) anterior-posterior and left-right axes and B) anterior-posterior and dorsal-ventral axes of the limpet mimic. Each point represents the resultant direction of a single strike event classified as a peck or push by the black oystercatcher during trials on 6 dates. Point colors indicate the net force in Newtons of the strike event.'}
# Plot all Pushes and Pecks on the same plot

library(circular, quietly = TRUE)
# Set up multiple plotting regions
split.screen(figs = rbind(c(0,0.85,0.5,1),
						c(0,0.85,0,0.5),
						c(0.85,1,0,1)))


shrinkval = 0.8
sepVal = 0.04
panelLetterAdj = -0.3
letterLine = 1.2
mymar = c(5,6,5,8)

cols = brewer.pal(9,'Greys')
cols = cols[3:9]
# Create color ramp palette function
pal = colorRampPalette(cols)

pecks = forceDir # no subset, use all Pushes and Pecks
# Order the peck data based on the absolute value of the 3-D peck force
pecks = pecks[order(abs(pecks$Norm)),]
# Generate a vector of color codes for the ordered force values
peckcols = pal(nrow(pecks))


# Make a plot of the distribution of fore-aft & left-right directional
# data for the peaks and pushes together.
# Convert angle data to circular object
hpecks <- circular(pecks$horizAngle, units='degrees',
		template = 'none')
par(xpd=TRUE)
par(family='serif')
par(mar = mymar)
# initial plot
thisplot = plot(hpecks, type = 'n', shrink = shrinkval, rotation = 'clock', 
		zero = pi/2, 
		axes=FALSE, tol = 0.01, control.circle = circle.control(n=5000))

# Angle labels
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		lty = 1, tcl.text = 0.15, at = NULL, labels = rep('',4), tcl = 0.1,
		lwd = 1.5)
par(xpd=TRUE)
# Body axis labels
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		labels=c('Anterior','Posterior'), tcl.text = -0.25,
		at = c(circular(c(90,270), units='degrees', template='none')))
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		labels=c('Right','Left'), tcl.text = -0.25, 
		at = c(circular(c(0,180), units='degrees', template='none')))
# Plot the stacked points
my.points.circular(hpecks, stack = TRUE, bins = 360, shrink =1.3, 
		rotation = 'counter', zero = pi/2,
		pch = 20, sep = sepVal, mycols = peckcols)

par(xpd=FALSE)
mtext(side = 3, text = 'A', cex = 2.5, adj = panelLetterAdj, line = letterLine)
# Add limpet image to center
addImg(imgTop,x = 0,y = 0,width = 1.2,interpolate=TRUE)

# Move to next split screen region
screen(2)

####################################################################
####################################################################
# Make a plot of the distribution of vertical and fore-aft directional
# data for the peaks and pushes together.

# Order the peck data based on the absolute value of the 3-D peck force
vpecks = pecks[order(abs(pecks$Norm)),]
# Generate a vector of color codes for the ordered force values
vpeckcols = pal(nrow(vpecks))


par(xpd=TRUE)
par(mar = mymar)
par(family='serif')
fpecks <- circular(vpecks$vertAngle, units='degrees',
				template = 'none')
plot2 = plot(fpecks, type = 'n', shrink = shrinkval, rotation = 'counter', 
		zero = 0, 
		axes = FALSE)
# Angle labels
axis.circular(template = 'none', units='degrees', zero = 0, lty = 1, 
		tcl.text = 0.20, at = NULL, labels = rep('',4), tcl = 0.1,
		lwd = 1.5)
# Body axis labels
axis.circular(template = 'none',units='degrees',zero = 0,rotation='counter', 
		labels=c('Ventral','Dorsal'), 
		tcl.text = -0.2,
		at = c(circular(c(270,90),units='degrees',template='none')))

axis.circular(template = 'none',units='degrees',zero = 0,rotation='counter', 
		labels=c('Anterior','Posterior'), 
		tcl.text = -0.45,
		at = c(circular(c(-7,185),units='degrees',template='none')))

my.points.circular(fpecks, stack = TRUE, bins = 360, shrink =1.3, 
		rotation = 'counter', zero = 0,
		pch = 20, plot.info = plot2, sep = sepVal, mycols = vpeckcols)	
mtext(side = 3, text = 'B', cex = 2.5, adj = panelLetterAdj, line = letterLine)
# Add Lottia image side view
addImg(imgSide,x = 0,y = 0.2,width = 1.7,interpolate=TRUE)

screen(3)
################################################################
# Add color bar
par(mar=c(6,0.1,6,2))
par(family='serif')
plot.new()
legend_image <- as.raster(matrix(rev(pal(nrow(vpecks)))))
rasterImage(legend_image, 0, 0, 0.4,1)
text(x = 0.30,
		y=plotrix::rescale(seq(2,max(vpecks$Norm),l=6),newrange=c(0,1)), 
		labels = round(seq(2,max(vpecks$Norm),l=6),dig=1), pos = 4)
mtext(side=4,text='Force (N)', line = 0.5)
close.screen(all.screens=TRUE)

# Unload circular package to avoid interference with mean() and sd() functions
detach('package:circular', unload=TRUE)

```



```{r circularAnglePushesOnlyPlot,fig.show='hide',cache=TRUE,echo=showcode,dpi=600, fig.width=7,fig.height = 9,fig.cap='Angular distribution of force vectors for pushes along the A) anterior-posterior and left-right axes and B) anterior-posterior and dorsal-ventral axes of the limpet mimic. Each point represents the resultant direction of a single strike event classified as a push by the black oystercatcher during trials on 6 dates.'}
# Plot of only the Pushes in horizontal and vertical planes
library(circular, quietly = TRUE)
par(mfrow=c(2,1))
shrinkval = 0.8
sepVal = 0.04
panelLetterAdj = 0.01
letterLine = 1.5
# Make a simple plot of the distribution of fore-aft & left-right directional
# data for the peaks and pushes together.
hpush <- circular(forceDir$horizAngle[forceDir$PeckPush == 'Push'], units='degrees',
		template = 'none')
par(xpd=TRUE)
thisplot = plot(hpush, type = 'n', shrink = shrinkval, rotation = 'clock', zero = pi/2, 
		axes=FALSE, tol = 0.01)
# Angle labels
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		lty = 1, tcl.text = 0.15, at = NULL, labels = rep('',4), tcl = 0.1,
		lwd = 1.5)
par(xpd=TRUE)
# Body axis labels
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		labels=c('Anterior','Posterior'), tcl.text = -0.25,
		at = c(circular(c(90,270), units='degrees', template='none')))
axis.circular(template = 'none', units='degrees', zero = pi/2, rotation='clock', 
		labels=c('Right','Left'), tcl.text = -0.25, 
		at = c(circular(c(0,180), units='degrees', template='none')))
# Plot the stacked points
points.circular(hpush, stack = TRUE, bins = 360, shrink =1.3, 
		rotation = 'counter', zero = pi/2,
		pch = 20, sep = sepVal)	
par(xpd=FALSE)
mtext(side = 3, text = 'A', cex = 2.5, adj = panelLetterAdj, line = letterLine)
# Add limpet image to center
addImg(imgTop,x = 0,y = 0,width = 1.2,interpolate=TRUE)

####################################################################
####################################################################
# Make a plot of the distribution of vertical and fore-aft directional
# data for the peaks and pushes together.
par(xpd=TRUE)
fpush <- circular(forceDir$vertAngle[forceDir$PeckPush == 'Push'], units='degrees',
				template = 'none')
plot2 = plot(fpush, type = 'n', shrink = shrinkval, rotation = 'counter', zero = 0, 
		axes = FALSE)
# Angle labels
axis.circular(template = 'none', units='degrees', zero = 0, lty = 1, 
		tcl.text = 0.20, at = NULL, labels = rep('',4), tcl = 0.1,
		lwd = 1.5)

# Body axis labels
axis.circular(template = 'none',units='degrees',zero = 0,rotation='counter', 
		labels=c('Ventral','Dorsal'), 
		tcl.text = -0.2,
		at = c(circular(c(270,90),units='degrees',template='none')))

axis.circular(template = 'none',units='degrees',zero = 0,rotation='counter', 
		labels=c('Anterior','Posterior'), 
		tcl.text = -0.45,
		at = c(circular(c(-7,185),units='degrees',template='none')))

points.circular(fpush, stack = TRUE, bins = 360, shrink =1.3, 
		rotation = 'counter', zero = 0,
		pch = 20, plot.info = plot2, sep = sepVal)	
mtext(side = 3, text = 'B', cex = 2.5, adj = panelLetterAdj, line = letterLine)
# Add Lottia image side view
addImg(imgSide,x = 0,y = 0.2,width = 1.7,interpolate=TRUE)

# Unload circular package to avoid interference with mean() and sd() functions
detach('package:circular', unload=TRUE)

```


```{r directionAOV, echo=showcode}
library(circular, quietly = TRUE)
cat('Test of mean angle of attack in the horizontal plane for pecks vs pushes.')
# Test of the mean angle of attach in the horizontal plane for pecks vs. pushes
print(aov.circular(h,group = forceDir$PeckPush, method="LRT"))
 
cat('\n\nTest of mean angle of attack in the vertical and \n 
anterior-posterior plane for pecks vs pushes.')
# Test of the mean angle of attack in the horizontal plane for pecks vs. pushes
print(aov.circular(f,group = forceDir$PeckPush, method="LRT"))

# Unload circular package to avoid interference with mean() and sd() functions
detach('package:circular', unload=TRUE)

```

```{r angleECDFplot, echo=showcode, dpi=300,fig.height = 7, fig.width = 5,fig.cap='Empirical cumulative density functions for angle (in radians) of pecks vs. pushes in the horizontal plane (top panel) and vertical plane (bottom panel).'}
library(circular, quietly = TRUE)
par(mfrow=c(2,1))
# Horizontal plane
plot.edf(hpecks, col = 'red', main = 'Horizontal plane', xlab = 'Radians',
		ylab='Cumulative probability', las = 1)
lines.edf(hpush, col = 'blue')
legend('topleft',legend=c('Pecks','Pushes'),col=c('red','blue'), lty = 1,
		)
 
## Vertical plane
plot.edf(fpecks, col = 'red', main = 'Vertical plane',
		xlab = 'Radians',ylab='Cumulative probability', las = 1)
lines.edf(fpush, col = 'blue')
legend('topleft',legend=c('Pecks','Pushes'),col=c('red','blue'), lty = 1)

# Unload circular package to avoid interference with mean() and sd() functions
detach('package:circular', unload=TRUE)
```


```{r DennyBlanchetteStationaryShearFit,echo=showcode,dpi=300,fig.width=7,fig.cap="Best-fit line of stationary L. gigantea dislodgement force in shear, from data in Denny & Blanchette 2000, J. Exp. Biol."}
# From Denny & Blanchette 2002 JEB
# Regression coefficients for dislodgement force as a function of aperture area
# Shear: 
# alpha = 76301
# Beta = 0.812

# For the equation F = alpha * aperture area ^ Beta
# or linearized as ln(F) = ln(alpha) + Beta*ln(aperature area) (Equation 2)
# 
# The regression coefs above are based on area measured in METERS^2, so you need
# to convert measured limpet aperture areas to sq. meters before you plug them
# into this equation.

alpha = 76301
Beta = 0.812
area = seq(0,20, by = 0.5)  # 0 to 20 cm^2 aperture area
area.m = area / 10000 # convert cm^2 to m^2
# Predict log forces (Newtons)
logForces = log(76301) + (Beta*log(area.m))
# Convert log forces to forces by taking exponent
Forces = exp(logForces)

plot(x = area.m * 10000, y = Forces, type = 'p', xlab = 'Aperture area (cm^2)',
		ylab = 'Force (N)', 
		main = 'From Denny and Blanchette 2000, stationary shear force',
		cex.main = 1,
		las = 1)
```


```{r fitShearStationaryDataPlot, echo=showcode,dpi=300,fig.width=7,fig.height=7,fig.cap='Forces applied in shear required to dislodge L. gigantea of various aperature areas. Raw data points reproduced from Denny & Blanchette 2000, J. Exp. Biol. The best fit line and 95% prediction interval are shown. The dashed horizontal line represents the largest shear force recorded by the captive oystercatcher in this experiment.'}
fdirDenny = './Data/Denny_Blanchette_2000_tenacity_data/'
Dennydata = read.csv(file=paste0(fdirDenny,
				'Lgigantea_shear_stationary_Denny_Blanchette_2000.csv'))

# Convert m^2 to cm^2
Dennydata$Area.cm2 = Dennydata$Area.m2 * 10000

modfit = lm(log(Force.N)~log(Area.cm2), data = Dennydata)
# ln(F) = ln(alpha) + Beta*ln(aperature area) 
alpha = exp(coef(modfit)[1])
beta = coef(modfit)[2]

newdat = data.frame(Area.cm2 = seq(0.1,18, by = 0.01))
# Generate 95% prediction intervals around the fitted regression
newdat[,2:4] = predict(modfit, newdata = newdat, interval='prediction')
names(newdat)[2:4] = c('fitted','lower95','upper95') # name columns

par(family = 'serif')
plot(x=newdat$Area.cm2,y = exp(newdat$fitted), type = 'l',
		ylim = c(0,800), las = 1, 
		ylab = 'Force (N)',
		xlab = '',
		xaxt = 'n',
		xaxs = 'i', yaxs = 'i')
# Create vector of x values for the polygon
xx = c(newdat$Area.cm2,rev(newdat$Area.cm2))	
#create vector of y values for the polygon using upper and lower limits
yy = c(exp(newdat$upper95),exp(rev(newdat$lower95)))
#plot polygon
polygon(xx,yy, col = rgb(0,0,0,0.4), border = NA)
# Plot the raw data from Denny & Blanchette
points(x=Dennydata$Area.cm2, y = Dennydata$Force.N, pch = 20)
# Plot a line showing the maximum horizontal (shearing) force imposed on the 
# limpet mimic by the captive oystercatcher.
abline(h = maxHorizForce, col = 'black', lwd = 2, lty = 2)
axis(side = 1, at = pretty(newdat$Area.cm2), labels = pretty(newdat$Area.cm2))
mtext(side = 1, text = expression(Area~'(cm'^2*')'), line = 2.5)
```

```{r maxAreacm2,echo=showcode}
# Find the value where the lower 95% prediction interval exceeds the
# maximum horizontal (shearing) force recorded on the transducer 
maxArea.cm2 = newdat$Area.cm2[max(which(exp(newdat$lower95) <= 
								maxHorizForce))] 

```

The largest shear force we measured on the limpet force transducer was
`r round(maxHorizForce,dig=2)` N. Using data from Denny & Blanchette, 2000,
*Journal of Experimental Biology*, we fit a power function to their measured
dislodgement forces applied in shear to *L. gigantea* that were stationary and
had been tapped to produce the highest tenacity. Based on the calculated 95%
prediction interval, the largest *L. gigantea* that might be dislodged by a
single pecking or pushing force applied in shear (parallel to the substratum) is
`r round(maxArea.cm2,digits = 2)` cm^2. 

The best fit line through the Denny and Blanchette 2000 data is of the 
form
$ln(Force) = ln(38.66) + 0.815\times ln(Area)$


Rachel provided aperture area estimates for L. gigantea that were successfully 
removed by the captive oystercatcher during feeding trials. The limpets had
been held overnight in high tide conditions after collection, and then were 
exposed to a 4 hour "low tide" (or no low tide) prior to being presented to 
the oystercatcher. Only a subset of the successfully eaten limpets have 
aperture area data.

```{r eatenApertureAreaData,echo=showcode, results='asis'}
eatenArea.cm2 = data.frame(Treatment = c(rep('CLT',7), rep('WLT',9), 
				rep('NLT',8)), 
		Length.cm = c(35.2,35,35,38.6,34.2,33.9,32.4,
				32.4,35.7,38.2,30.2,37.5,33.3,39.0,38.7,33.1,
				35.7,35.2,37.8,38.8,38.7,39,39.4,33.5),
		Aperture.cm2 = c(7.39,7.27,7.31,rep(NA,4),
				6.51,7.5,8.51,5.76,7.93,4.87,8.53,8.73,6.36,
				7.41,8.29,7.9,9.63,9.13,9.13,9.06,NA))
kable(eatenArea.cm2, 
		caption="Approximate foot aperture area (cm^2) for L. gigantea eaten by the captive
oystercatcher. Treatments are Cold Low Tide (CLT), Warm Low Tide (WLT), or 
No Low Tide (NLT). Aperture area data were missing for 4 CLT limpets and 1 
NLT limpet (all shell lengths were recorded).")
```

```{r ShearStationayDataWithAperturesPlot,echo=showcode,dev=c('png','pdf'),dpi=300,fig.width=7,fig.height=7,fig.cap='Forces applied in shear required to dislodge L. gigantea of various aperture areas with a single pull in tension. Raw data points reproduced from Denny & Blanchette 2000, J. Exp. Biol. The best fit line and 95% prediction interval are shown. The dashed horizontal line represents the largest shear force recorded by the captive oystercatcher in this experiment. Arrows on the horizontal axis mark the sizes of L. gigantea successfully dislodged by the captive oystercatcher using multiple strikes.'}

# Convert m^2 to cm^2
Dennydata$Area.cm2 = Dennydata$Area.m2 * 10000

modfit = lm(log(Force.N)~log(Area.cm2), data = Dennydata)
# ln(F) = ln(alpha) + Beta*ln(aperature area) 
alpha = exp(coef(modfit)[1])
beta = coef(modfit)[2]

newdat = data.frame(Area.cm2 = seq(0.1,18, by = 0.01))
# Generate 95% prediction intervals around the fitted regression
newdat[,2:4] = predict(modfit, newdata = newdat, interval='prediction')
names(newdat)[2:4] = c('fitted','lower95','upper95') # name columns

par(family = 'serif')
plot(x=newdat$Area.cm2,y = exp(newdat$fitted), type = 'l',
		ylim = c(0,800), las = 1, 
		ylab = 'Force (N)',
		xlab = '',
		xaxt = 'n',
		xaxs = 'i', yaxs = 'i')
# Create vector of x values for the polygon
xx = c(newdat$Area.cm2,rev(newdat$Area.cm2))	
#create vector of y values for the polygon using upper and lower limits
yy = c(exp(newdat$upper95),exp(rev(newdat$lower95)))
#plot polygon
polygon(xx,yy, col = rgb(0,0,0,0.4), border = NA)
# Plot the raw data from Denny & Blanchette
points(x=Dennydata$Area.cm2, y = Dennydata$Force.N, pch = 20)
# Plot a line showing the maximum horizontal (shearing) force imposed on the 
# limpet mimic by the captive oystercatcher.
abline(h = maxHorizForce, col = 'black', lwd = 2, lty = 2)
axis(side = 1, at = pretty(newdat$Area.cm2), labels = pretty(newdat$Area.cm2))
mtext(side = 1, text = expression(Area~'(cm'^2*')'), line = 2.5)
# Add arrows along the x-axis showing the aperture areas of L. gig that 
# the captive oystercatcher managed to remove in the feeding trials, using 
# multiple pecks (so a single maximum force within the prediction interval
# probably wasn't necessary).
par(xpd=TRUE)
arrows(x0 = eatenArea.cm2$Aperture.cm2, 
		x1 = eatenArea.cm2$Aperture.cm2,
		y0 = rep(-30,nrow(eatenArea.cm2)),
		y1 = rep(0,nrow(eatenArea.cm2)), 
				angle = 30, cex = 1.5,
				length = 0.1, lwd = 2)
par(xpd=FALSE)
```
